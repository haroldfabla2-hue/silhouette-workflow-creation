# Tutorial Completo: Creaci√≥n de Workflows en Silhouette

## üéØ Objetivo del Tutorial

Este tutorial te guiar√° paso a paso para crear workflows complejos en Silhouette Workflow Platform. Al final, habr√°s creado tres workflows de diferentes niveles de complejidad:

1. **B√°sico**: Processing de datos de formularios
2. **Intermedio**: Sincronizaci√≥n de datos con APIs externas  
3. **Avanzado**: Workflow inteligente con IA y auto-scaling

---

## üèóÔ∏è Fundamentos del Editor de Workflows

### Interface del Editor

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  üîÑ Silhouette Workflow Designer                           [üíæ Save] [‚ñ∂Ô∏è Run]  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ Nodes Panel ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Canvas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ Prop. ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ  ‚îÇ                                         ‚îÇ  ‚îÇ Panel   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ üìã General    ‚îÇ  ‚îÇ  [‚óè] Start      [üì°] API         [üì§] End ‚îÇ  ‚îÇ         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îú Start       ‚îÇ  ‚îÇ     ‚îÇ               ‚îÇ                ‚îÇ    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îú End         ‚îÇ  ‚îÇ     ‚ñº               ‚ñº                ‚îÇ    ‚îÇ  ‚îÇNode ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îú Manual      ‚îÇ  ‚îÇ  [üîÑ] Logic    [üíæ] Store              ‚îÇ    ‚îÇ  ‚îÇSelec‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îî ‚úì           ‚îÇ  ‚îÇ     ‚îÇ               ‚îÇ                ‚îÇ    ‚îÇ  ‚îÇted  ‚îÇ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ  ‚îÇ     ‚ñº               ‚ñº                ‚îÇ    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ
‚îÇ  ‚îÇ üîå Connectors ‚îÇ  ‚îÇ  [üìä] Transform  [‚ùå] Error            ‚îÇ    ‚îÇ         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îú HTTP        ‚îÇ  ‚îÇ                                         ‚îÇ    ‚îÇ  ‚öôÔ∏è Config ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îú Webhook     ‚îÇ  ‚îÇ                                         ‚îÇ  ‚îÇ         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îú Database    ‚îÇ  ‚îÇ                                         ‚îÇ  ‚îÇ  üîó Flow ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îú Email       ‚îÇ  ‚îÇ                                         ‚îÇ  ‚îÇ  [Start] ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îî ‚úì           ‚îÇ  ‚îÇ                                         ‚îÇ  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ  ‚îÇ                                         ‚îÇ  ‚îÇ  [Logic] ‚îÇ ‚îÇ
‚îÇ  ‚îÇ üß† AI/ML      ‚îÇ  ‚îÇ                                         ‚îÇ  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îú ML Model    ‚îÇ  ‚îÇ                                         ‚îÇ  ‚îÇ  [API]   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îú Predict     ‚îÇ  ‚îÇ                                         ‚îÇ  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îî ‚úì           ‚îÇ  ‚îÇ                                         ‚îÇ  ‚îÇ  [End]   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ               ‚îÇ  ‚îÇ                                         ‚îÇ  ‚îÇ         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ üìä Data       ‚îÇ  ‚îÇ                                         ‚îÇ  ‚îÇ  üìà Stats‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îú Transform   ‚îÇ  ‚îÇ                                         ‚îÇ  ‚îÇ  ‚è±Ô∏è Time ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îú Filter      ‚îÇ  ‚îÇ                                         ‚îÇ  ‚îÇ  üêõ Debug‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚îî ‚úì           ‚îÇ  ‚îÇ                                         ‚îÇ  ‚îÇ         ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îÇ  Status: Ready   ‚îÇ  Last Saved: 2 min ago  ‚îÇ  Validation: ‚úÖ Pass         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Tipos de Nodos

#### 1. Nodos de Control
- **Start**: Punto de entrada del workflow
- **End**: Punto de salida
- **Manual**: Intervenci√≥n manual requerida
- **Error**: Manejo de errores

#### 2. Nodos de Conectores
- **HTTP/HTTPS**: Solicitudes web
- **Webhook**: Recibir datos de terceros
- **Database**: Conectar con bases de datos
- **Email**: Env√≠o de correos
- **FTP/SFTP**: Transferencia de archivos

#### 3. Nodos de Datos
- **Transform**: Transformar datos
- **Filter**: Filtrar datos
- **Sort**: Ordenar datos
- **Aggregate**: Agregar datos

#### 4. Nodos de L√≥gica
- **Switch**: Condicional simple
- **Router**: Enrutamiento m√∫ltiple
- **Loop**: Bucles
- **Parallel**: Ejecuci√≥n paralela

#### 5. Nodos de IA/ML
- **ML Model**: Predicciones
- **Optimization**: Optimizaci√≥n de workflows
- **Auto-scale**: Escalado inteligente

---

## üìù Workflow B√°sico: Procesamiento de Formularios

### Descripci√≥n
Crear un workflow que procese datos de formularios, valide la informaci√≥n, la almacene en base de datos y env√≠e confirmaci√≥n por email.

### Objetivo de Negocio
Automatizar el procesamiento de solicitudes de soporte t√©cnico de clientes.

### Diagrama del Workflow
```
[Webhook] ‚Üí [Validate] ‚Üí [Transform] ‚Üí [Database] ‚Üí [Send Email] ‚Üí [End]
    ‚Üì           ‚Üì            ‚Üì           ‚Üì           ‚Üì
   Input    Validation   Formatting   Storage    Notification
```

### Paso 1: Crear el Proyecto

1. Ve a **Workflows ‚Üí Crear Workflow**
2. Selecciona **"Workflow Vac√≠o"**
3. Configura la informaci√≥n b√°sica:
   ```
   Nombre: "Procesamiento de Formularios de Soporte"
   Descripci√≥n: "Procesa solicitudes de soporte t√©cnico de clientes"
   Categor√≠a: "Customer Service"
   Tags: formulario, soporte, email
   ```

### Paso 2: Configurar Nodo Webhook

1. **Agregar nodo Webhook**:
   - Arrastra el nodo **"Webhook"** desde el panel **"Connectors"**
   - Col√≥calo en la parte izquierda del canvas

2. **Configurar propiedades**:
   ```
   General:
     Nombre: "Webhook de Formulario"
     Descripci√≥n: "Recibir datos del formulario de soporte"
   
   Webhook Settings:
     Method: POST
     Path: /support-form
     Authentication: None
     Rate Limit: 100 requests/hour
   
   Data Structure:
     {
       "customer_name": "string (required)",
       "customer_email": "email (required)",
       "ticket_title": "string (required)",
       "ticket_description": "text (required)",
       "priority": "low|medium|high|urgent",
       "category": "billing|technical|general"
     }
   
   Validation:
     ‚úì Required fields check
     ‚úì Email format validation
     ‚úì JSON schema validation
   ```

3. **Conectar con Start**:
   - Conecta el nodo **Start** ‚Üí **Webhook**

### Paso 3: Configurar Validaci√≥n

1. **Agregar nodo de validaci√≥n**:
   - Arrastra el nodo **"Filter"** desde **"Data"**
   - Conecta **Webhook** ‚Üí **Filter**

2. **Configurar reglas de validaci√≥n**:
   ```
   Filter Rules:
     Rule 1: customer_name.length > 0
     Rule 2: customer_email.match(/^[^\s@]+@[^\s@]+\.[^\s@]+$/)
     Rule 3: ticket_title.length >= 5
     Rule 4: ticket_description.length >= 20
     Rule 5: priority in ['low', 'medium', 'high', 'urgent']
     Rule 6: category in ['billing', 'technical', 'general']
   
   On Valid: Continue to next node
   On Invalid: 
     - Log error
     - Send response: "Datos de formulario inv√°lidos"
     - Route to Error node
   ```

### Paso 4: Transformar Datos

1. **Agregar nodo Transform**:
   - Arrastra el nodo **"Transform"** desde **"Data"**
   - Conecta **Filter** ‚Üí **Transform**

2. **Configurar transformaci√≥n**:
   ```
   Input: {{webhook_data}}
   
   Transform Function:
   {
     "ticket_id": "TKT-" + Date.now(),
     "customer": {
       "name": input.customer_name.trim(),
       "email": input.customer_email.toLowerCase()
     },
     "request": {
       "title": input.ticket_title,
       "description": input.ticket_description,
       "category": input.category,
       "priority": input.priority
     },
     "metadata": {
       "created_at": new Date().toISOString(),
       "source": "web_form",
       "ip_address": "{{request.ip}}",
       "user_agent": "{{request.user_agent}}"
     },
     "status": "new"
   }
   ```

### Paso 5: Almacenar en Base de Datos

1. **Agregar nodo Database**:
   - Arrastra el nodo **"Database"** desde **"Connectors"**
   - Conecta **Transform** ‚Üí **Database**

2. **Configurar conexi√≥n**:
   ```
   Database Type: PostgreSQL
   Connection:
     Host: postgres
     Port: 5432
     Database: haasdb
     User: haas
     Password: haaspass
     SSL: false
   
   Table: support_tickets
   
   Insert Query:
   INSERT INTO support_tickets (
     ticket_id, customer_name, customer_email, 
     title, description, category, priority, 
     status, created_at, metadata
   ) VALUES (
     {{transform_data.ticket_id}},
     {{transform_data.customer.name}},
     {{transform_data.customer.email}},
     {{transform_data.request.title}},
     {{transform_data.request.description}},
     {{transform_data.request.category}},
     {{transform_data.request.priority}},
     {{transform_data.status}},
     {{transform_data.metadata.created_at}},
     {{JSON.stringify(transform_data.metadata)}}
   )
   
   Return: ticket_id
   ```

### Paso 6: Enviar Email de Confirmaci√≥n

1. **Agregar nodo Email**:
   - Arrastra el nodo **"Email"** desde **"Connectors"**
   - Conecta **Database** ‚Üí **Email**

2. **Configurar email**:
   ```
   SMTP Configuration:
     Server: smtp.gmail.com
     Port: 587
     Security: STARTTLS
     Username: noreply@tuempresa.com
     Password: {{EMAIL_PASSWORD}}
   
   Email Settings:
     From: soporte@tuempresa.com
     To: {{transform_data.customer.email}}
     Subject: "Confirmaci√≥n: Ticket #{{db_result.ticket_id}}"
   
   Template (HTML):
   <!DOCTYPE html>
   <html>
   <head>
     <title>Confirmaci√≥n de Ticket</title>
     <style>
       .header { background: #2563eb; color: white; padding: 20px; }
       .content { padding: 20px; }
       .ticket-info { background: #f3f4f6; padding: 15px; margin: 10px 0; }
       .footer { background: #f9fafb; padding: 15px; text-align: center; }
     </style>
   </head>
   <body>
     <div class="header">
       <h1>Ticket de Soporte Creado</h1>
     </div>
     <div class="content">
       <p>Hola {{transform_data.customer.name}},</p>
       <p>Hemos recibido tu solicitud de soporte y hemos creado el siguiente ticket:</p>
       
       <div class="ticket-info">
         <strong>ID de Ticket:</strong> {{db_result.ticket_id}}<br>
         <strong>T√≠tulo:</strong> {{transform_data.request.title}}<br>
         <strong>Prioridad:</strong> {{transform_data.request.priority}}<br>
         <strong>Categor√≠a:</strong> {{transform_data.request.category}}<br>
         <strong>Estado:</strong> {{transform_data.status}}
       </div>
       
       <p>Nuestro equipo de soporte revisar√° tu solicitud y te contactar√° pronto.</p>
       <p>Puedes hacer seguimiento de tu ticket en: <a href="https://soporte.tuempresa.com/ticket/{{db_result.ticket_id}}">https://soporte.tuempresa.com/ticket/{{db_result.ticket_id}}</a></p>
     </div>
     <div class="footer">
       <p>Si tienes preguntas, responde a este email.</p>
       <p>¬© 2025 Tu Empresa S.L. - Equipo de Soporte</p>
     </div>
   </body>
   </html>
   ```

### Paso 7: Configurar Manejo de Errores

1. **Agregar nodo de Error**:
   - Arrastra el nodo **"Error"** al canvas
   - Conecta todos los puntos de fallo ‚Üí **Error**

2. **Configurar Error Handler**:
   ```
   Error Actions:
     1. Log error details
     2. Send notification to admin
     3. Return error response to client
   
   Notification Email:
     To: admin@tuempresa.com
     Subject: "Error en Workflow: Procesamiento de Formularios"
     Body: Error details and workflow context
   ```

### Paso 8: Validar y Probar

1. **Validar workflow**:
   - Haz clic en **"Validar"** 
   - Revisa que no hay errores de configuraci√≥n

2. **Probar con datos de ejemplo**:
   ```json
   {
     "customer_name": "Juan P√©rez",
     "customer_email": "juan@cliente.com",
     "ticket_title": "Error en login",
     "ticket_description": "No puedo iniciar sesi√≥n desde hace 2 horas",
     "priority": "high",
     "category": "technical"
   }
   ```

3. **Publicar workflow**:
   - Haz clic en **"Publicar"**
   - El webhook estar√° disponible en: `https://tuempresa.com/api/support-form`

### Resultado del Workflow B√°sico

```
‚úÖ Workflow Creado: "Procesamiento de Formularios de Soporte"
üîó Webhook URL: https://tuempresa.com/api/support-form
üìä Estado: Activo
‚è±Ô∏è Tiempo de procesamiento: ~2.3 segundos
üìß Email enviado: ‚úÖ Confirmaci√≥n autom√°tica
üíæ Datos almacenados: ‚úÖ En base de datos
```

---

## üåê Workflow Intermedio: Sincronizaci√≥n de Datos con APIs

### Descripci√≥n
Crear un workflow que sincronice datos de clientes entre Salesforce y un sistema interno, maneje conflictos y notifique cambios importantes.

### Objetivo de Negocio
Mantener sincronizaci√≥n autom√°tica de datos de clientes entre sistemas empresariales.

### Diagrama del Workflow
```
[Scheduler] ‚Üí [Fetch Salesforce] ‚Üí [Fetch Internal] ‚Üí [Compare] ‚Üí [Update/Sync] ‚Üí [Log Changes] ‚Üí [Send Report] ‚Üí [End]
     ‚Üì              ‚Üì                  ‚Üì              ‚Üì           ‚Üì              ‚Üì              ‚Üì
  Time-based    API Call          Database       Logic     Conflicts      Audit         Admin
  Trigger       OAuth2            Query         Rules      Resolution     Trail         Notification
```

### Paso 1: Configurar Programaci√≥n

1. **Agregar nodo Scheduler**:
   - Arrastra el nodo **"Manual"** (cambia a Scheduler)
   - Configura:
   ```
   Schedule Type: Cron
   Cron Expression: "0 2 * * *" (2:00 AM daily)
   Timezone: UTC
   Description: "Daily customer sync at 2 AM"
   ```

### Paso 2: Configurar Conexi√≥n con Salesforce

1. **Agregar nodo HTTP Request**:
   - Nombre: "Fetch Salesforce Customers"
   - Conectar **Scheduler** ‚Üí **HTTP Request**

2. **Configurar Salesforce API**:
   ```
   HTTP Configuration:
     Method: GET
     URL: https://your-instance.salesforce.com/services/data/v57.0/query/
     Authentication: OAuth 2.0
   
   OAuth 2.0 Settings:
     Client ID: {{SF_CLIENT_ID}}
     Client Secret: {{SF_CLIENT_SECRET}}
     Access Token: {{SF_ACCESS_TOKEN}}
     Token Refresh: Auto-refresh enabled
   
   Query Parameters:
     q: SELECT Id, Name, Email, Phone, AccountId, CreatedDate, LastModifiedDate FROM Contact WHERE Email != null
   
   Headers:
     Authorization: Bearer {{sf_access_token}}
     Content-Type: application/json
   
   Response Handling:
     Pagination: Automatic
     Retry Logic: 3 attempts with exponential backoff
     Rate Limiting: Respect Salesforce API limits
   ```

### Paso 3: Obtener Datos Internos

1. **Agregar nodo Database Query**:
   - Nombre: "Fetch Internal Customers"
   - Conectar **HTTP Request** ‚Üí **Database Query**

2. **Configurar consulta**:
   ```
   Database: PostgreSQL
   Query:
   SELECT 
     id, 
     salesforce_id, 
     name, 
     email, 
     phone, 
     account_id,
     created_at,
     updated_at,
     sync_status
   FROM customers 
   WHERE email IS NOT NULL
   ORDER BY updated_at DESC;
   
   Connection: Internal DB (haasdb)
   ```

### Paso 4: Comparar y Detectar Cambios

1. **Agregar nodo Transform**:
   - Nombre: "Compare Data Sources"
   - Conectar **Database Query** ‚Üí **Transform**

2. **Configurar l√≥gica de comparaci√≥n**:
   ```
   Input:
     salesforce_data: {{http_request.response.records}}
     internal_data: {{db_query.result}}
   
   Comparison Logic:
   {
     // Identificar registros nuevos
     new_records: salesforce_data.filter(sf => 
       !internal_data.find(int => int.salesforce_id === sf.Id)
     ),
     
     // Identificar registros actualizados
     updated_records: salesforce_data.filter(sf => {
       const internal = internal_data.find(int => int.salesforce_id === sf.Id);
       return internal && new Date(sf.LastModifiedDate) > new Date(internal.updated_at);
     }),
     
     // Identificar registros eliminados
     deleted_records: internal_data.filter(int => 
       !salesforce_data.find(sf => sf.Id === int.salesforce_id) && int.sync_status !== 'deleted'
     ),
     
     // Identificar conflictos
     conflicts: salesforce_data.filter(sf => {
       const internal = internal_data.find(int => int.salesforce_id === sf.Id);
       return internal && (
         sf.Name !== internal.name ||
         sf.Email !== internal.email ||
         sf.Phone !== internal.phone
       );
     })
   }
   
   Output: {
     sync_summary: {
       total_salesforce: salesforce_data.length,
       total_internal: internal_data.length,
       new_records: new_records.length,
       updated_records: updated_records.length,
       deleted_records: deleted_records.length,
       conflicts: conflicts.length
     },
     changes: {
       to_create: new_records,
       to_update: updated_records,
       to_delete: deleted_records,
       conflicts: conflicts
     }
   }
   ```

### Paso 5: Resolver Conflictos

1. **Agregar nodo Router**:
   - Nombre: "Route by Change Type"
   - Conectar **Transform** ‚Üí **Router**

2. **Configurar enrutamiento**:
   ```
   Routes:
     Route 1: "has_conflicts && conflicts.length > 0"
       ‚Üí Conflict Resolution
     
     Route 2: "has_changes && conflicts.length === 0"
       ‚Üí Apply Changes
     
     Route 3: "no_changes"
       ‚Üí Log No Changes
   
   Default Route: Log Unexpected Data
   ```

### Paso 6: Resoluci√≥n de Conflictos

1. **Agregar nodo Switch**:
   - Nombre: "Conflict Resolution Strategy"
   - Conectar **Router** ‚Üí **Switch**

2. **Configurar estrategias**:
   ```
   Conflict Resolution Options:
   
   Option 1: "Salesforce as Source of Truth"
     - Always prefer Salesforce data
     - Log override decision
     - Auto-apply changes
   
   Option 2: "Internal as Source of Truth"
     - Always prefer internal data
     - Log override decision
     - Sync back to Salesforce
   
   Option 3: "Manual Review Required"
     - Create review task
     - Pause sync process
     - Notify admin for manual resolution
   
   Option 4: "Timestamp-based Resolution"
     - Compare LastModifiedDate vs updated_at
     - Use most recent data
     - Log resolution decision
   
   Configuration:
   Resolution Strategy: {{WORKFLOW_CONFIG.conflict_strategy}}
   Review Required: conflicts.length > 5 || critical_fields_changed
   Notification: admin@tuempresa.com
   ```

### Paso 7: Aplicar Sincronizaci√≥n

1. **Agregar nodos paralelos**:
   - **Create Records**: Para registros nuevos
   - **Update Records**: Para registros actualizados
   - **Delete Records**: Para registros eliminados

2. **Configurar Create Records**:
   ```
   Database Operation: INSERT
   Query:
   INSERT INTO customers (
     salesforce_id, name, email, phone, 
     account_id, created_at, updated_at, 
     sync_status, last_sync_at
   ) VALUES (
     {{change.salesforce_id}},
     {{change.Name}},
     {{change.Email}},
     {{change.Phone}},
     {{change.AccountId}},
     NOW(),
     NOW(),
     'active',
     NOW()
   );
   
   Batch Size: 100
   Continue on Error: false
   Error Handling: Log and continue with next batch
   ```

3. **Configurar Update Records**:
   ```
   Database Operation: UPDATE
   Query:
   UPDATE customers SET 
     name = {{change.Name}},
     email = {{change.Email}},
     phone = {{change.Phone}},
     account_id = {{change.AccountId}},
     updated_at = NOW(),
     last_sync_at = NOW(),
     sync_status = 'active'
   WHERE salesforce_id = {{change.Id}};
   
   Batch Size: 100
   Continue on Error: false
   ```

4. **Configurar Delete Records**:
   ```
   Database Operation: UPDATE (soft delete)
   Query:
   UPDATE customers SET 
     sync_status = 'deleted',
     deleted_at = NOW(),
     updated_at = NOW()
   WHERE salesforce_id = {{change.salesforce_id}};
   
   Backup First: true
   Retention Period: 30 days
   ```

### Paso 8: Logging y Auditor√≠a

1. **Agregar nodo Database (Log Table)**:
   - Nombre: "Log Sync Results"
   - Conectar **Switch** ‚Üí **Database (Log)**

2. **Configurar logging**:
   ```
   Table: customer_sync_log
   
   Log Query:
   INSERT INTO customer_sync_log (
     sync_date, workflow_id, sync_type,
     records_processed, records_created, records_updated, 
     records_deleted, conflicts_found, conflicts_resolved,
     execution_time_ms, status, details
   ) VALUES (
     NOW(),
     '{{workflow.id}}',
     'scheduled_daily',
     {{summary.total_processed}},
     {{summary.created_count}},
     {{summary.updated_count}},
     {{summary.deleted_count}},
     {{summary.conflicts_count}},
     {{summary.conflicts_resolved}},
     {{execution_time}},
     '{{status}}',
     '{{JSON.stringify(summary)}}'
   );
   ```

### Paso 9: Generar Reportes

1. **Agregar nodo Email**:
   - Nombre: "Send Sync Report"
   - Conectar **Database (Log)** ‚Üí **Email**

2. **Configurar reporte**:
   ```
   Recipients: 
     - admin@tuempresa.com
     - data-team@tuempresa.com
   
   Subject: "Reporte de Sincronizaci√≥n - {{date}}"
   
   Email Template:
   <html>
   <head>
     <title>Reporte de Sincronizaci√≥n de Clientes</title>
     <style>
       .summary-table { border-collapse: collapse; width: 100%; }
       .summary-table th, .summary-table td { 
         border: 1px solid #ddd; 
         padding: 8px; 
         text-align: left; 
       }
       .summary-table th { background-color: #f2f2f2; }
       .success { color: green; }
       .warning { color: orange; }
       .error { color: red; }
     </style>
   </head>
   <body>
     <h2>Reporte de Sincronizaci√≥n - {{sync_date}}</h2>
     
     <h3>Resumen</h3>
     <table class="summary-table">
       <tr>
         <th>M√©trica</th>
         <th>Valor</th>
         <th>Estado</th>
       </tr>
       <tr>
         <td>Total Registros Procesados</td>
         <td>{{summary.total_processed}}</td>
         <td class="success">‚úÖ</td>
       </tr>
       <tr>
         <td>Registros Creados</td>
         <td>{{summary.created_count}}</td>
         <td class="success">‚úÖ</td>
       </tr>
       <tr>
         <td>Registros Actualizados</td>
         <td>{{summary.updated_count}}</td>
         <td class="success">‚úÖ</td>
       </tr>
       <tr>
         <td>Registros Eliminados</td>
         <td>{{summary.deleted_count}}</td>
         <td class="warning">‚ö†Ô∏è</td>
       </tr>
       <tr>
         <td>Conflictos Encontrados</td>
         <td>{{summary.conflicts_count}}</td>
         <td class="{{conflict_class}}">{{conflict_icon}}</td>
       </tr>
       <tr>
         <td>Tiempo de Ejecuci√≥n</td>
         <td>{{execution_time}} ms</td>
         <td class="success">‚úÖ</td>
       </tr>
     </table>
     
     {{#if conflicts}}
     <h3>Conflictos Detectados</h3>
     <p>Se detectaron {{conflicts.length}} conflictos que requieren revisi√≥n manual.</p>
     <ul>
       {{#each conflicts}}
       <li>
         <strong>{{this.Name}}</strong> ({{this.Email}})
         <br>√öltima modificaci√≥n SF: {{this.LastModifiedDate}}
         <br>√öltima modificaci√≥n Interna: {{this.updated_at}}
       </li>
       {{/each}}
     </ul>
     {{/if}}
     
     <p>Para m√°s detalles, consulte el dashboard de sincronizaci√≥n.</p>
   </body>
   </html>
   ```

### Paso 10: Validar y Probar

1. **Ejecutar workflow manualmente** para probar

2. **Monitorear primera ejecuci√≥n**:
   - Ver logs en tiempo real
   - Revisar base de datos para confirmar sincronizaci√≥n
   - Verificar emails de reporte

### Resultado del Workflow Intermedio

```
‚úÖ Workflow Creado: "Sincronizaci√≥n de Clientes Salesforce"
‚è∞ Programaci√≥n: Diario a las 2:00 AM
üîó Integraci√≥n: Salesforce API
üìä Estado: Activo y Monitoreado
‚è±Ô∏è Tiempo promedio: ~45 segundos
üìß Reportes: Autom√°ticos diarios
üîÑ Sync Status: ‚úÖ Bidireccional
üîç Conflictos: Resoluci√≥n autom√°tica
```

---

## ü§ñ Workflow Avanzado: Inteligencia Artificial y Auto-scaling

### Descripci√≥n
Crear un workflow inteligente que use ML para predecir demanda, optimice recursos autom√°ticamente y escale infraestructura seg√∫n la carga predicted.

### Objetivo de Negocio
Implementar un sistema de auto-scaling inteligente que optimice costos y performance basado en predicciones de IA.

### Diagrama del Workflow
```
[Load Monitor] ‚Üí [ML Predict] ‚Üí [Optimize Resources] ‚Üí [Auto-scale] ‚Üí [Performance Check] ‚Üí [ML Learn] ‚Üí [Log Metrics] ‚Üí [End]
      ‚Üì              ‚Üì              ‚Üì                ‚Üì               ‚Üì              ‚Üì              ‚Üì
  Real-time     Forecasting     AI Decision     Infrastructure   Validation   Model Update    Analytics
  Metrics       Algorithm       Engine          Manager          AI Model     Feedback Loop   & Reporting
```

### Paso 1: Monitoreo en Tiempo Real

1. **Agregar nodo Scheduler (High Frequency)**:
   - Configuraci√≥n:
   ```
   Schedule: Every 5 minutes
   Type: Recurring
   Timezone: UTC
   Description: "High-frequency load monitoring"
   ```

2. **Agregar nodo HTTP Request (Metrics API)**:
   - Conectar **Scheduler** ‚Üí **HTTP Request**
   - Configurar:
   ```
   API Endpoint: /api/system/metrics
   Method: GET
   Headers:
     Authorization: Bearer {{MONITORING_TOKEN}}
   
   Metrics Collected:
   - CPU utilization (%)
   - Memory usage (%)
   - Active connections
   - Request rate (req/min)
   - Response time (ms)
   - Error rate (%)
   - Queue depth
   - Database connections
   ```

### Paso 2: Predicci√≥n con ML

1. **Agregar nodo AI/ML**:
   - Nombre: "ML Load Prediction"
   - Conectar **HTTP Request** ‚Üí **AI/ML**

2. **Configurar modelo ML**:
   ```
   Model Type: time-series-forecasting
   Model Name: load-predictor-v2
   Input Features:
     - historical_cpu: [CPU usage last 24h]
     - historical_memory: [Memory usage last 24h]
     - historical_requests: [Request rate last 24h]
     - time_of_day: Current time
     - day_of_week: Current day
     - is_business_hours: Boolean
     - recent_events: Event data
   
   Prediction Horizon: 1 hour ahead
   Confidence Threshold: 0.85
   Update Model: Enabled
   ```

3. **Configurar predicci√≥n**:
   ```
   ML Request:
   {
     "model": "load-predictor-v2",
     "input": {
       "current_metrics": {{http_response.data}},
       "historical_window": "24h",
       "prediction_horizon": "60min"
     },
     "config": {
       "confidence_threshold": 0.85,
       "return_explanations": true
     }
   }
   
   Expected Output:
   {
     "predictions": [
       {
         "timestamp": "2025-11-09T09:00:00Z",
         "cpu_predicted": 75.2,
         "memory_predicted": 68.4,
         "requests_predicted": 450,
         "confidence": 0.89,
         "explanation": "High demand expected during business hours"
       }
     ],
     "model_version": "v2.1.3",
     "overall_confidence": 0.87
   }
   ```

### Paso 3: Motor de Optimizaci√≥n

1. **Agregar nodo AI/ML (Optimization Engine)**:
   - Nombre: "Resource Optimization"
   - Conectar **ML Predict** ‚Üí **Optimization Engine**

2. **Configurar algoritmo de optimizaci√≥n**:
   ```
   Optimization Algorithm: genetic-algorithm
   Objective Functions:
     1. Minimize cost (weight: 0.4)
     2. Maintain performance SLA (weight: 0.4)
     3. Minimize resource waste (weight: 0.2)
   
   Constraints:
     - Max CPU per pod: 80%
     - Max memory per pod: 85%
     - Min pods: 2
     - Max pods: 20
     - Scale up cooldown: 5 minutes
     - Scale down cooldown: 10 minutes
   
   Decision Variables:
     - target_replicas
     - cpu_limit_per_pod
     - memory_limit_per_pod
     - auto_scaling_policy
   
   Cost Model:
     - Cost per pod per hour: $0.05
     - Load balancer cost: $0.02/hour
     - Storage cost: $0.01/GB/hour
   ```

3. **Configurar optimizaci√≥n**:
   ```
   Optimization Request:
   {
     "algorithm": "genetic-algorithm",
     "objective": "multi-objective",
     "constraints": {
       "max_replicas": 20,
       "min_replicas": 2,
       "max_cpu": 80,
       "max_memory": 85,
       "cooldown_up": 300,
       "cooldown_down": 600
     },
     "current_state": {
       "replicas": {{current_replicas}},
       "cpu_utilization": {{ml_prediction.current_cpu}},
       "memory_utilization": {{ml_prediction.current_memory}},
       "cost_per_hour": {{current_cost}}
     },
     "predicted_load": {{ml_prediction.predictions}},
     "business_rules": {
       "peak_hours_scale_aggressive": true,
       "off_peak_aggressive_scaling": false,
       "cost_optimization_priority": "medium"
     }
   }
   ```

### Paso 4: Auto-scaling Inteligente

1. **Agregar nodo Custom (Auto-scaler)**:
   - Nombre: "Intelligent Auto-scaler"
   - Conectar **Optimization Engine** ‚Üí **Auto-scaler**

2. **Configurar escalado**:
   ```
   Scaling Actions:
   
   Scale Up Decision:
   If prediction.confidence > 0.8 AND
      predicted_cpu > 70% AND
      cooldown_completed AND
      not_scaling_recently
   
   Then:
     - Calculate optimal replicas: {{optimization.target_replicas}}
     - Apply scaling gradually: +2 pods per action
     - Update load balancer configuration
     - Send notifications
   
   Scale Down Decision:
   If prediction.confidence > 0.8 AND
      predicted_cpu < 40% AND
      current_replicas > min_replicas AND
      cooldown_completed
   
   Then:
     - Calculate optimal replicas: {{optimization.target_replicas}}
     - Apply scaling conservatively: -1 pod per action
     - Wait for traffic drain
     - Update monitoring alerts
   
   Safety Measures:
     - Minimum replicas: 2
     - Maximum replicas: 20
     - Cooldown periods: 5-10 minutes
     - Health check validation: Required
     - Rollback on failure: Automatic
   ```

### Paso 5: Validaci√≥n de Performance

1. **Agregar nodo AI/ML (Performance Validator)**:
   - Nombre: "Performance Validation"
   - Conectar **Auto-scaler** ‚Üí **Performance Validator**

2. **Configurar validaci√≥n**:
   ```
   Performance Metrics:
   - Response time (target: < 200ms)
   - Error rate (target: < 0.1%)
   - Throughput (target: maintain or improve)
   - Resource utilization (CPU < 80%, Memory < 85%)
   - Cost per transaction (monitor changes)
   
   Validation Rules:
   Rule 1: response_time < 200ms (95th percentile)
   Rule 2: error_rate < 0.1%
   Rule 3: cpu_utilization < 80%
   Rule 4: memory_utilization < 85%
   Rule 5: cost_efficiency_maintained
   
   Success Criteria: All rules pass
   Warning Criteria: 1-2 rules borderline
   Failure Criteria: 3+ rules fail
   
   Actions:
   - Success: Log success, continue to learning
   - Warning: Log warning, continue to learning
   - Failure: Rollback scaling, alert admin
   ```

### Paso 6: Aprendizaje Continuo

1. **Agregar nodo AI/ML (Model Updater)**:
   - Nombre: "Continuous Learning"
   - Conectar **Performance Validator** ‚Üí **Model Updater**

2. **Configurar feedback loop**:
   ```
   Learning Data:
   - Predicted values
   - Actual values
   - Performance outcomes
   - Scaling decisions and results
   - Cost impact
   - User experience metrics
   
   Model Update Conditions:
   - Performance deviates > 10% from prediction
   - Model accuracy drops below 0.8
   - New patterns detected
   - Quarterly updates
   
   Learning Algorithm: online-learning
   Batch Size: 1000 samples
   Update Frequency: Every 100 executions
   Model Versioning: Automatic
   A/B Testing: Enabled for model versions
   
   Feedback Collection:
   {
     "prediction_id": "{{prediction.id}}",
     "predicted_values": {{ml_prediction.output}},
     "actual_values": {
       "cpu": {{performance.actual_cpu}},
       "memory": {{performance.actual_memory}},
       "response_time": {{performance.actual_response_time}},
       "cost": {{performance.actual_cost}}
     },
     "scaling_decision": {
       "action": "{{scaling.action}}",
       "replicas_before": {{scaling.replicas_before}},
       "replicas_after": {{scaling.replicas_after}},
       "outcome": "{{scaling.outcome}}"
     },
     "performance_impact": {
       "improved": {{performance.improved}},
       "degraded": {{performance.degraded}},
       "neutral": {{performance.neutral}}
     },
     "user_feedback": {{performance.user_satisfaction}}
   }
   ```

### Paso 7: Logging y Analytics

1. **Agregar nodo Database**:
   - Nombre: "Log AI Decisions"
   - Conectar **Model Updater** ‚Üí **Database**

2. **Configurar analytics**:
   ```
   Log Tables:
   - ai_decisions_log
   - scaling_actions_log
   - performance_metrics_log
   - model_performance_log
   
   Decision Log Query:
   INSERT INTO ai_decisions_log (
     decision_id, timestamp, workflow_id,
     predicted_load, optimization_result,
     scaling_action, performance_before,
     performance_after, confidence_score,
     cost_impact, learning_feedback
   ) VALUES (
     '{{decision.id}}',
     NOW(),
     '{{workflow.id}}',
     {{JSON.stringify(predicted_load)}},
     {{JSON.stringify(optimization_result)}},
     '{{scaling.action}}',
     {{JSON.stringify(performance_before)}},
     {{JSON.stringify(performance_after)}},
     {{decision.confidence}},
     {{cost_impact}},
     {{JSON.stringify(learning_data)}}
   );
   ```

### Paso 8: Dashboard y Alertas

1. **Agregar nodo HTTP Request (Dashboard Update)**:
   - Nombre: "Update AI Dashboard"
   - Conectar **Database** ‚Üí **HTTP Request**

2. **Configurar dashboard**:
   ```
   Dashboard API: /api/ai/dashboard/update
   
   Update Data:
   {
     "timestamp": "{{now}}",
     "ai_decisions_today": {{ai_decisions_count}},
     "successful_scalings": {{successful_scalings}},
     "performance_improvements": {{performance_improvements}},
     "cost_savings": {{cost_savings}},
     "model_accuracy": {{model_accuracy}},
     "prediction_confidence": {{avg_confidence}},
     "trends": {
       "scaling_frequency": "{{scaling_trend}}",
       "performance_trend": "{{performance_trend}}",
       "cost_efficiency": "{{cost_efficiency_trend}}"
     }
   }
   ```

### Paso 9: Configurar Alertas Inteligentes

1. **Agregar nodo Email/Slack (Smart Alerts)**:
   - Nombre: "Intelligent Alerting"
   - Conectar **Performance Validator** ‚Üí **Smart Alerts**

2. **Configurar alertas**:
   ```
   Alert Conditions:
   
   Critical Alerts:
   - Model accuracy < 0.7
   - Performance degradation > 20%
   - Scaling failures
   - Cost spike > 50%
   
   Warning Alerts:
   - Model accuracy < 0.8
   - Predictions inconsistent with reality
   - High prediction confidence but wrong outcomes
   - Unusual scaling patterns
   
   Info Alerts:
   - Daily AI performance summary
   - New model versions deployed
   - Learning milestones reached
   
   Smart Alerting Rules:
   - Use ML to reduce false positives
   - Batch similar alerts
   - Smart timing (don't alert at 3 AM unless critical)
   - Include suggested actions in alerts
   ```

### Paso 10: Validar y Optimizar

1. **Probar el workflow**:
   - Ejecutar en modo test con datos hist√≥ricos
   - Monitorear predicciones vs realidad
   - Ajustar umbrales y par√°metros

2. **M√©tricas de √âxito**:
   ```
   Performance Metrics:
   - Prediction accuracy: > 85%
   - Cost reduction: > 25%
   - Response time improvement: > 15%
   - Resource utilization optimization: > 20%
   - False positive alerts: < 5%
   
   Business Metrics:
   - Reduced manual intervention: 90%
   - Improved resource efficiency: 25%
   - Better cost predictability: 95%
   - Enhanced user experience: 20% improvement
   ```

### Resultado del Workflow Avanzado

```
‚úÖ Workflow Creado: "AI-Powered Auto-scaling"
ü§ñ IA/ML: Load prediction + optimization + learning
‚ö° Auto-scaling: Inteligente y optimizado por costos
üìä Monitoreo: 5 minutos con predicciones 1 hora
üîÑ Aprendizaje: Continuo con feedback loops
üí∞ Optimizaci√≥n: Costos + Performance + Eficiencia
üìà Dashboard: Tiempo real con insights de IA
üö® Alertas: Inteligentes con acciones sugeridas
```

---

## üéØ Mejores Pr√°cticas

### 1. Dise√±o de Workflows

```
‚úÖ DO:
- Usa nombres descriptivos para nodos
- Agrupa nodos relacionados
- Implementa manejo de errores robusto
- Documenta workflows complejos
- Usa versionado para cambios importantes

‚ùå DON'T:
- Crear workflows con m√°s de 50 nodos
- Conectar directamente start a end
- Ignorar el manejo de errores
- Usar datos hardcodeados
- Crear dependencias circulares
```

### 2. Performance y Escalabilidad

```
‚úÖ DO:
- Implementa timeouts apropiados
- Usa batch processing para datos grandes
- Implementa rate limiting
- Monitorea memory usage
- Usa conexiones pooling

‚ùå DON'T:
- Hacer llamadas sincr√≥nicas a APIs lentas
- Cargar grandes datasets en memoria
- Ignorar l√≠mites de API
- Crear infinite loops
- Usar timeouts muy altos
```

### 3. Seguridad

```
‚úÖ DO:
- Valida todos los inputs
- Usa conexiones seguras (HTTPS/TLS)
- Implementa autenticaci√≥n robusta
- Encripta datos sensibles
- Mant√©n logs de auditor√≠a

‚ùå DON'T:
- Exponer credenciales en logs
- Usar conexiones sin encriptar
- Ignorar validaci√≥n de datos
- Compartir tokens de API
- Almacenar passwords en plain text
```

### 4. Monitoreo y Debugging

```
‚úÖ DO:
- Implementa logging detallado
- Usa m√©tricas de negocio
- Configura alertas apropiadas
- Mant√©n historiales de ejecuci√≥n
- Usa el debug mode durante desarrollo

‚ùå DON'T:
- Ignorar warnings del sistema
- No monitorear m√©tricas clave
- Usar logs de solo error
- Ignorar patrones de uso
- Desactivar alertas cr√≠ticas
```

---

## üèÜ Conclusi√≥n

Has completado la creaci√≥n de tres workflows de diferentes niveles de complejidad:

1. **B√°sico**: Procesamiento de formularios con validaci√≥n y notificaciones
2. **Intermedio**: Sincronizaci√≥n de datos con manejo de conflictos
3. **Avanzado**: Sistema de auto-scaling inteligente con IA/ML

### Pr√≥ximos Pasos

- **Explorar Conectores**: Implementa workflows con bases de datos, APIs empresariales
- **Funciones de IA**: Experimenta con optimizaci√≥n de workflows y recomendaciones
- **Workflows Complejos**: Crea workflows con cientos de nodos y l√≥gica avanzada
- **Integraci√≥n**: Conecta con sistemas empresariales existentes
- **Optimizaci√≥n**: Usa analytics para mejorar performance de workflows

### Recursos Adicionales

- üìñ [Documentaci√≥n Completa de la API](api-reference.md)
- üîß [Gu√≠a de Administraci√≥n](admin-guide.md)
- ü§ñ [Funciones de IA/ML](ai-guide.md)
- üí¨ [Comunidad y Soporte](community.md)

**¬°Felicidades! Ya tienes las bases para crear workflows complejos y poderosos en Silhouette Workflow Platform! üéâ**
