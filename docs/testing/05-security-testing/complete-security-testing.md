# Security Testing - Completo

## DescripciÃ³n General

El **Security Testing Framework** de Silhouette Workflow Creation es un sistema integral de testing de seguridad que garantiza que la plataforma estÃ© protegida contra amenazas y vulnerabilidades. Este framework implementa Static Application Security Testing (SAST), Dynamic Application Security Testing (DAST), Interactive Application Security Testing (IAST), dependency scanning, container security scanning y penetration testing automatizado.

## Arquitectura del Security Testing

### Componentes del Sistema de Security Testing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                SECURITY TESTING FRAMEWORK                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ SAST            â”‚  â”‚ DAST            â”‚  â”‚ IAST         â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚              â”‚ â”‚
â”‚  â”‚ â€¢ Code Analysis â”‚  â”‚ â€¢ Runtime Scan  â”‚  â”‚ â€¢ Runtime     â”‚ â”‚
â”‚  â”‚ â€¢ SonarQube     â”‚  â”‚ â€¢ OWASP ZAP     â”‚  â”‚ â€¢ Interactive â”‚ â”‚
â”‚  â”‚ â€¢ Semgrep       â”‚  â”‚ â€¢ Burp Suite    â”‚  â”‚ â€¢ Real-time   â”‚ â”‚
â”‚  â”‚ â€¢ CodeQL        â”‚  â”‚ â€¢ Nikto         â”‚  â”‚ â€¢ Context     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ DEPENDENCY      â”‚  â”‚ CONTAINER       â”‚  â”‚ INFRASTRUCT. â”‚ â”‚
â”‚  â”‚ SCANNING        â”‚  â”‚ SCANNING        â”‚  â”‚ SECURITY     â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚              â”‚ â”‚
â”‚  â”‚ â€¢ Snyk          â”‚  â”‚ â€¢ Trivy         â”‚  â”‚ â€¢ Kubernetes â”‚ â”‚
â”‚  â”‚ â€¢ npm audit     â”‚  â”‚ â€¢ Clair         â”‚  â”‚ â€¢ Terraform  â”‚ â”‚
â”‚  â”‚ â€¢ Safety        â”‚  â”‚ â€¢ Anchore       â”‚  â”‚ â€¢ Cloud      â”‚ â”‚
â”‚  â”‚ â€¢ Bundler Audit â”‚  â”‚ â€¢ Twistlock     â”‚  â”‚ â€¢ Network    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ PENETRATION     â”‚  â”‚ COMPLIANCE      â”‚  â”‚ THREAT       â”‚ â”‚
â”‚  â”‚ TESTING         â”‚  â”‚ TESTING         â”‚  â”‚ MODELING     â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚              â”‚ â”‚
â”‚  â”‚ â€¢ Automated     â”‚  â”‚ â€¢ SOX           â”‚  â”‚ â€¢ STRIDE     â”‚ â”‚
â”‚  â”‚ â€¢ Manual        â”‚  â”‚ â€¢ GDPR          â”‚  â”‚ â€¢ DREAD      â”‚ â”‚
â”‚  â”‚ â€¢ OWASP Top 10  â”‚  â”‚ â€¢ ISO 27001     â”‚  â”‚ â€¢ Attack     â”‚ â”‚
â”‚  â”‚ â€¢ Custom        â”‚  â”‚ â€¢ SOC 2         â”‚  â”‚ â€¢ Vectors    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 1. Static Application Security Testing (SAST)

### SonarQube Security Configuration

```yaml
# sonar-project.properties
# SonarQube Security Project Configuration
sonar.projectKey=silhouette-workflow-security
sonar.projectName=Silhouette Workflow Security Analysis
sonar.projectVersion=1.0.0
sonar.organization=silhouette-organization

# Source code configuration
sonar.sources=src
sonar.tests=tests
sonar.test.inclusions=**/*.test.ts,**/*.test.js,**/*.spec.ts,**/*.spec.js
sonar.exclusions=**/*.d.ts,**/node_modules/**,**/dist/**,**/build/**

# Language-specific configuration
sonar.typescript.lcov.reportPaths=coverage/lcov.info
sonar.javascript.lcov.reportPaths=coverage/lcov.info
sonar.coverage.exclusions=**/*.test.ts,**/*.test.js,**/*.spec.ts,**/*.spec.js,**/mocks/**,**/__mocks__/**

# Security analysis configuration
sonar.sast.analyzer.enabled=true
sonar.sast.analyzer.project.key=silhouette-workflow-security
sonar.sast.analyzer.organization.key=silhouette-organization
sonar.sast.analyzer.organization.token=${SONAR_SAST_TOKEN}

# Security rules configuration
sonar.sast.rules.java.enabled=true
sonar.sast.rules.javascript.enabled=true
sonar.sast.rules.typescript.enabled=true

# Security hotspot analysis
sonar.security.hotspots.minScore=0.7
sonar.security.hotspots.newCode.referenceBranch=main

# Security vulnerability rules
sonar.security.vulnerabilities.minScore=0.5
sonar.security.vulnerabilities.newCode.referenceBranch=main

# External security scanning tools integration
sonar.externalSecurityIssues.reportPaths=security-report.json
```

### Custom Security Rules Configuration

```json
// .sonarqube/custom-security-rules.json
{
  "rules": [
    {
      "key": "javascript:S3649",
      "name": "Database endpoints should not be accessible",
      "description": "Direct database access should be prevented through API endpoints",
      "severity": "CRITICAL",
      "type": "VULNERABILITY"
    },
    {
      "key": "javascript:S3651",
      "name": "JWT tokens should not be stored in localStorage",
      "description": "JWT tokens should be stored in httpOnly cookies for security",
      "severity": "MAJOR",
      "type": "VULNERABILITY"
    },
    {
      "key": "javascript:S3652",
      "name": "Passwords should not be hardcoded",
      "description": "Passwords and secrets should not be hardcoded in source code",
      "severity": "CRITICAL",
      "type": "VULNERABILITY"
    },
    {
      "key": "typescript:S3653",
      "name": "SQL injection prevention",
      "description": "SQL queries should use parameterized statements",
      "severity": "CRITICAL",
      "type": "VULNERABILITY"
    },
    {
      "key": "typescript:S3654",
      "name": "XSS prevention",
      "description": "User input should be properly sanitized to prevent XSS",
      "severity": "MAJOR",
      "type": "VULNERABILITY"
    },
    {
      "key": "typescript:S3655",
      "name": "CSRF protection",
      "description": "State-changing operations should include CSRF tokens",
      "severity": "MAJOR",
      "type": "VULNERABILITY"
    },
    {
      "key": "typescript:S3656",
      "name": "Insecure random number generation",
      "description": "Use cryptographically secure random number generators",
      "severity": "MAJOR",
      "type": "VULNERABILITY"
    },
    {
      "key": "typescript:S3657",
      "name": "Insecure deserialization",
      "description": "Object deserialization should be done safely",
      "severity": "CRITICAL",
      "type": "VULNERABILITY"
    },
    {
      "key": "typescript:S3658",
      "name": "Weak cryptography",
      "description": "Use strong cryptographic algorithms and proper key management",
      "severity": "CRITICAL",
      "type": "VULNERABILITY"
    },
    {
      "key": "typescript:S3659",
      "name": "Missing input validation",
      "description": "All user inputs should be validated",
      "severity": "MAJOR",
      "type": "VULNERABILITY"
    }
  ],
  "hotspots": [
    {
      "key": "javascript:S5887",
      "name": "Using experimental features",
      "description": "Avoid using experimental JavaScript features without proper analysis",
      "severity": "MINOR",
      "type": "SECURITY_HOTSPOT"
    },
    {
      "key": "javascript:S5888",
      "name": "Using eval() function",
      "description": "eval() function should be avoided due to security risks",
      "severity": "MAJOR",
      "type": "SECURITY_HOTSPOT"
    },
    {
      "key": "typescript:S5889",
      "name": "Insecure file operations",
      "description": "File operations should be done with proper validation",
      "severity": "MAJOR",
      "type": "SECURITY_HOTSPOT"
    },
    {
      "key": "typescript:S5890",
      "name": "Network security",
      "description": "Network requests should use secure protocols",
      "severity": "MAJOR",
      "type": "SECURITY_HOTSPOT"
    }
  ]
}
```

### CodeQL Security Analysis Configuration

```yaml
# .codeql/codeql-config.yml
name: "Silhouette Security CodeQL"

queries:
  - uses: security-extended
  - uses: security-and-quality
  - uses: accuracy-upgrade
  - uses: maintainability-upgrade

paths:
  - "src/"
  - "tests/"

paths-ignore:
  - "src/types/"
  - "src/config/"
  - "node_modules/"

disable-default-queries: false

query-filters:
  - include:
      kind: problem
      precision: high
  - exclude:
      id: js/useless-assignment-to-local
```

### Semgrep Security Rules

```yaml
# .semgrep/security-rules.yml
rules:
  - id: hardcoded-credentials
    pattern-either:
      - pattern: |
          const $PASSWORD = "$PASSWORD"
      - pattern: |
          const $API_KEY = "$API_KEY"
      - pattern: |
          password: "$PASSWORD"
      - pattern: |
          apiKey: "$API_KEY"
    message: "Hardcoded credentials detected"
    severity: ERROR
    languages: [javascript, typescript]
    metadata:
      cwe: "CWE-798: Use of Hard-coded Credentials"

  - id: sql-injection
    pattern-either:
      - pattern: |
          db.query(`SELECT * FROM $TABLE WHERE id = ${$ID}`)
      - pattern: |
          knex($DB).select("*").from($TABLE).where("id", $ID)
    message: "Potential SQL injection vulnerability"
    severity: ERROR
    languages: [javascript, typescript]
    metadata:
      cwe: "CWE-89: SQL Injection"
      owasp: "A03:2021 â€“ Injection"

  - id: xss-vulnerability
    pattern-either:
      - pattern: |
          document.write($INPUT)
      - pattern: |
          innerHTML = $INPUT
      - pattern: |
          dangerouslySetInnerHTML = { __html: $INPUT }
    message: "Potential XSS vulnerability"
    severity: ERROR
    languages: [javascript, typescript]
    metadata:
      cwe: "CWE-79: Cross-site Scripting"
      owasp: "A03:2021 â€“ Injection"

  - id: eval-usage
    pattern: |
      eval($CODE)
    message: "Use of eval() function is dangerous"
    severity: ERROR
    languages: [javascript, typescript]
    metadata:
      cwe: "CWE-94: Code Injection"

  - id: insecure-random
    pattern-either:
      - pattern: |
          Math.random()
      - pattern: |
          new Date().getTime()
    message: "Use cryptographically secure random number generation"
    severity: ERROR
    languages: [javascript, typescript]
    metadata:
      cwe: "CWE-338: Use of Cryptographically Weak PRNG"

  - id: jwt-hardcoded-secret
    pattern: |
      jwt.sign($PAYLOAD, "$SECRET")
    message: "Hardcoded JWT secret detected"
    severity: ERROR
    languages: [javascript, typescript]
    metadata:
      cwe: "CWE-798: Use of Hard-coded Credentials"
      owasp: "A07:2021 â€“ Identification and Authentication Failures"

  - id: express-ssl-redirect-disabled
    pattern: |
      app.use(express())
    metavariable-pattern:
      metavariable: $EXPRESS
      pattern: app.use($EXPRESS)
    message: "Express SSL redirect middleware is not configured"
    severity: WARNING
    languages: [javascript, typescript]
    metadata:
      owasp: "A02:2021 â€“ Cryptographic Failures"

  - id: missing-helmet-security
    pattern: |
      import helmet from "helmet"
    metavariable-pattern:
      metavariable: $HELMET
      pattern: |
        import $HELMET from "helmet"
    message: "Helmet security headers are not configured"
    severity: WARNING
    languages: [javascript, typescript]
    metadata:
      owasp: "A05:2021 â€“ Security Misconfiguration"

  - id: cors-origin-wildcard
    pattern: |
      cors({
        origin: "*"
      })
    message: "CORS configuration allows all origins"
    severity: ERROR
    languages: [javascript, typescript]
    metadata:
      owasp: "A05:2021 â€“ Security Misconfiguration"

  - id: bcrypt-rounds-low
    pattern-either:
      - pattern: |
          bcrypt.hash($PASSWORD, 8)
      - pattern: |
          bcrypt.hash($PASSWORD, 10)
    message: "bcrypt rounds should be at least 12"
    severity: ERROR
    languages: [javascript, typescript]
    metadata:
      cwe: "CWE-522: Insufficiently Protected Credentials"
```

## 2. Dynamic Application Security Testing (DAST)

### OWASP ZAP Full Security Scan

```yaml
# .zap/zap-full-scan.yml
# ZAP Full Security Scan Configuration
params:
  - zapapitesturl: https://silhouette-workflow.example.com
  - zapapitestuser: test@silhouette-workflow.com
  - zapapitestpass: testpassword123
  - zapapiformmethod: post
  - zapapiformdata: username=test@silhouette-workflow.com&password=testpassword123&Login=Login

# Authentication configuration
authentication:
  method: "form"
  parameters:
    target: "https://silhouette-workflow.example.com/api/auth/login"
    username: "test@silhouette-workflow.com"
    password: "testpassword123"

# Spider configuration
spider:
  maxDepth: 3
  maxChildren: 100
  threadCount: 5
  delayInMs: 200
  maxDuration: 15m

# Active scan configuration
activeScan:
  policy: "Default Policy"
  attackStrength: "Medium"
  threadPerHost: 10
  maxScanTimeInMins: 30

# Rules to skip during scan
rules:
  # Skip rules that don't indicate security issues
  - rule_id: 2
    reason: 'Used for passive scanning'
  - rule_id: 3
    reason: 'Used for passive scanning'
  
  # Skip false positive rules
  - rule_id: 10015
    reason: 'Sensitive information in HTTP referrer header - False positive'
  - rule_id: 10016
    reason: 'Web Browser XSS Protection Not Enabled - Modern browsers handle this'
  - rule_id: 10019
    reason: 'Content Type is not specified - False positive for APIs'
  - rule_id: 10020
    reason: 'X-Frame-Options Header Missing - Intentionally disabled for embedding'
  - rule_id: 10021
    reason: 'X-Content-Type-Options header missing - False positive'
  - rule_id: 10030
    reason: 'Cookie No Secure Flag - Only applicable for HTTPS in production'
  - rule_id: 10032
    reason: 'HTTPS Content Available via HTTP - Only in development'
  - rule_id: 10033
    reason: 'X-Download-Options Header Missing - IE-specific, not relevant'
  - rule_id: 10034
    reason: 'Strict-Transport-Security Missing - Only relevant for HTTPS'
  - rule_id: 10036
    reason: 'HTTP Server Response Header - Informational only'
  - rule_id: 10038
    reason: 'Content Security Policy Missing - Requires careful CSP configuration'
  - rule_id: 10039
    reason: 'X-Content-Type-Options Header Missing - False positive'

# API specific configuration
api:
  target: "https://silhouette-workflow.example.com/api"
  includePaths:
    - "/api/*"
    - "/auth/*"
    - "/workflows/*"
    - "/analytics/*"
  excludePaths:
    - "/health"
    - "/metrics"
    - "/docs/*"

# Authentication test cases
authTestCases:
  - name: "Invalid Login Attempt"
    request:
      method: "POST"
      url: "/api/auth/login"
      body: |
        {
          "email": "invalid@email.com",
          "password": "invalidpassword"
        }
    expected:
      statusCode: 401
      responseTime: < 1000

  - name: "SQL Injection in Login"
    request:
      method: "POST"
      url: "/api/auth/login"
      body: |
        {
          "email": "admin' OR '1'='1",
          "password": "anything"
        }
    expected:
      statusCode: 400
      responseTime: < 1000

  - name: "XSS in Search"
    request:
      method: "GET"
      url: "/api/workflows?search=<script>alert('xss')</script>"
    expected:
      statusCode: 400
      responseTime: < 1000

# Business logic test cases
businessLogic:
  - name: "Unauthorized Workflow Access"
    request:
      method: "GET"
      url: "/api/workflows/12345"
    expected:
      statusCode: 401

  - name: "Rate Limit Testing"
    request:
      method: "POST"
      url: "/api/auth/login"
      repeat: 100
      delay: 100
    expected:
      statusCode: 429
      responseTime: < 2000

  - name: "Large Payload Testing"
    request:
      method: "POST"
      url: "/api/workflows"
      body: |
        {
          "name": "A",
          "description": "A".repeat(10000),
          "triggers": [],
          "actions": []
        }
    expected:
      statusCode: 413
      responseTime: < 2000

# Output configuration
output:
  format: "sarif"
  file: "zap-security-report.sarif"
  includeRequest: true
  includeResponse: true
  includeTag: true
```

### ZAP API Security Testing Script

```python
#!/usr/bin/env python3
# zap-api-security-test.py
import requests
import json
import time
import base64
from datetime import datetime

class ZAPSecurityTester:
    def __init__(self, zap_url, target_url, auth_token=None):
        self.zap_url = zap_url
        self.target_url = target_url
        self.auth_token = auth_token
        self.session = requests.Session()
        
        if auth_token:
            self.session.headers.update({
                'Authorization': f'Bearer {auth_token}'
            })
    
    def start_spider(self, url=None, max_depth=3):
        """Start ZAP spider to discover URLs"""
        if not url:
            url = self.target_url
        
        print(f"Starting spider for: {url}")
        
        response = self.session.get(
            f"{self.zap_url}/JSON/spider/action/scan/",
            params={
                'url': url,
                'maxDepth': max_depth
            }
        )
        
        if response.status_code == 200:
            result = response.json()
            scan_id = result.get('scan')
            print(f"Spider started with ID: {scan_id}")
            return scan_id
        else:
            print(f"Failed to start spider: {response.status_code}")
            return None
    
    def wait_for_spider(self, scan_id, timeout=300):
        """Wait for spider to complete"""
        print("Waiting for spider to complete...")
        
        start_time = time.time()
        while time.time() - start_time < timeout:
            response = self.session.get(
                f"{self.zap_url}/JSON/spider/view/status/",
                params={'scanId': scan_id}
            )
            
            if response.status_code == 200:
                result = response.json()
                status = result.get('status')
                print(f"Spider status: {status}")
                
                if status == '100':
                    print("Spider completed successfully")
                    return True
                elif int(status) > 90:
                    print("Spider almost complete, waiting...")
                    time.sleep(5)
                else:
                    print(f"Spider progress: {status}%")
                    time.sleep(10)
            else:
                print(f"Failed to get spider status: {response.status_code}")
                time.sleep(5)
        
        print("Spider timeout reached")
        return False
    
    def start_active_scan(self, url=None):
        """Start active scan"""
        if not url:
            url = self.target_url
        
        print(f"Starting active scan for: {url}")
        
        response = self.session.get(
            f"{self.zap_url}/JSON/ascan/action/scan/",
            params={
                'url': url,
                'recurse': True,
                'inScopeOnly': True,
                'scanPolicyName': 'Default Policy',
                'method': 'GET'
            }
        )
        
        if response.status_code == 200:
            result = response.json()
            scan_id = result.get('scan')
            print(f"Active scan started with ID: {scan_id}")
            return scan_id
        else:
            print(f"Failed to start active scan: {response.status_code}")
            return None
    
    def wait_for_active_scan(self, scan_id, timeout=600):
        """Wait for active scan to complete"""
        print("Waiting for active scan to complete...")
        
        start_time = time.time()
        while time.time() - start_time < timeout:
            response = self.session.get(
                f"{self.zap_url}/JSON/ascan/view/status/",
                params={'scanId': scan_id}
            )
            
            if response.status_code == 200:
                result = response.json()
                status = result.get('status')
                print(f"Active scan status: {status}")
                
                if status == '100':
                    print("Active scan completed successfully")
                    return True
                elif int(status) > 90:
                    print("Active scan almost complete, waiting...")
                    time.sleep(10)
                else:
                    print(f"Active scan progress: {status}%")
                    time.sleep(15)
            else:
                print(f"Failed to get active scan status: {response.status_code}")
                time.sleep(10)
        
        print("Active scan timeout reached")
        return False
    
    def get_alerts(self, baseurl=None, risk_level='Medium'):
        """Get alerts from the scan"""
        if not baseurl:
            baseurl = self.target_url
        
        print(f"Retrieving {risk_level} alerts for: {baseurl}")
        
        response = self.session.get(
            f"{self.zap_url}/JSON/alert/view/alerts/",
            params={
                'baseurl': baseurl,
                'start': 0,
                'count': 9999,
                'riskId': self._get_risk_id(risk_level)
            }
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            print(f"Failed to get alerts: {response.status_code}")
            return None
    
    def _get_risk_id(self, risk_level):
        """Convert risk level to ZAP risk ID"""
        risk_map = {
            'Informational': '0',
            'Low': '1',
            'Medium': '2',
            'High': '3'
        }
        return risk_map.get(risk_level, '2')
    
    def generate_report(self, output_file, format='json'):
        """Generate security report"""
        print(f"Generating {format} report: {output_file}")
        
        response = self.session.get(
            f"{self.zap_url}/OTHER/core/other/jsonreport/"
        )
        
        if response.status_code == 200:
            with open(output_file, 'w') as f:
                f.write(response.text)
            print(f"Report saved to: {output_file}")
            return True
        else:
            print(f"Failed to generate report: {response.status_code}")
            return False

def main():
    # Configuration
    zap_url = "http://localhost:8080"
    target_url = "https://silhouette-workflow.example.com"
    auth_token = None  # Set if authentication is required
    
    # Initialize ZAP tester
    tester = ZAPSecurityTester(zap_url, target_url, auth_token)
    
    try:
        # Step 1: Start spider
        spider_id = tester.start_spider(target_url, max_depth=3)
        if not spider_id:
            print("Failed to start spider")
            return 1
        
        # Step 2: Wait for spider to complete
        if not tester.wait_for_spider(spider_id):
            print("Spider did not complete successfully")
            return 1
        
        # Step 3: Start active scan
        scan_id = tester.start_active_scan(target_url)
        if not scan_id:
            print("Failed to start active scan")
            return 1
        
        # Step 4: Wait for active scan to complete
        if not tester.wait_for_active_scan(scan_id):
            print("Active scan did not complete successfully")
            return 1
        
        # Step 5: Get alerts
        medium_alerts = tester.get_alerts(risk_level='Medium')
        high_alerts = tester.get_alerts(risk_level='High')
        
        # Step 6: Generate report
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"security_report_{timestamp}.json"
        tester.generate_report(report_file)
        
        # Step 7: Print summary
        print("\n=== Security Scan Summary ===")
        if medium_alerts and 'alerts' in medium_alerts:
            print(f"Medium risk issues: {len(medium_alerts['alerts'])}")
        
        if high_alerts and 'alerts' in high_alerts:
            print(f"High risk issues: {len(high_alerts['alerts'])}")
        
        print(f"Full report saved to: {report_file}")
        
    except Exception as e:
        print(f"Error during security testing: {str(e)}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())
```

### Custom Security Test Cases

```typescript
// security-tests/custom-security-tests.test.ts
import request from 'supertest';
import { createApp } from '../utils/create-app';
import { getTestToken } from '../utils/auth-helpers';

describe('Security Tests', () => {
  let app: Express;
  let authToken: string;
  let adminToken: string;

  beforeAll(async () => {
    app = createApp();
    authToken = await getTestToken('user@silhouette-workflow.com', 'password123');
    adminToken = await getTestToken('admin@silhouette-workflow.com', 'admin123');
  });

  describe('Authentication Security', () => {
    it('should prevent SQL injection in login', async () => {
      const sqlInjectionPayloads = [
        "' OR '1'='1",
        "admin'/*",
        "'; DROP TABLE users; --",
        "' UNION SELECT * FROM users--",
        "1' AND (SELECT COUNT(*) FROM users) > 0--"
      ];

      for (const payload of sqlInjectionPayloads) {
        const response = await request(app)
          .post('/api/auth/login')
          .send({
            email: payload,
            password: 'test123'
          })
          .expect(400);

        expect(response.body.success).toBe(false);
        expect(response.body.error).toContain('validation');
      }
    });

    it('should prevent brute force attacks', async () => {
      const maxAttempts = 5;
      const email = 'brute-force-test@silhouette-workflow.com';

      for (let i = 0; i < maxAttempts + 2; i++) {
        const response = await request(app)
          .post('/api/auth/login')
          .send({
            email: email,
            password: `invalid-password-${i}`
          })
          .expect(i < maxAttempts ? 401 : 429);

        if (i >= maxAttempts) {
          expect(response.body.error).toContain('rate limit');
        }
      }
    });

    it('should implement proper session management', async () => {
      // Login and get token
      const loginResponse = await request(app)
        .post('/api/auth/login')
        .send({
          email: 'session-test@silhouette-workflow.com',
          password: 'password123'
        })
        .expect(200);

      const token = loginResponse.body.data.token;

      // Use token for valid request
      await request(app)
        .get('/api/auth/profile')
        .set('Authorization', `Bearer ${token}`)
        .expect(200);

      // Try to use the same token after logout
      await request(app)
        .post('/api/auth/logout')
        .set('Authorization', `Bearer ${token}`)
        .expect(200);

      // Token should now be invalid
      await request(app)
        .get('/api/auth/profile')
        .set('Authorization', `Bearer ${token}`)
        .expect(401);
    });

    it('should not leak sensitive information in error messages', async () => {
      const response = await request(app)
        .post('/api/auth/login')
        .send({
          email: 'nonexistent@silhouette-workflow.com',
          password: 'somepassword'
        })
        .expect(401);

      expect(response.body.error).not.toContain('password');
      expect(response.body.error).not.toContain('database');
      expect(response.body.error).not.toContain('sql');
      expect(response.body.error).toContain('Invalid credentials');
    });
  });

  describe('Authorization Security', () => {
    it('should prevent unauthorized access to resources', async () => {
      // Try to access another user's workflow
      await request(app)
        .get('/api/workflows/12345')
        .set('Authorization', `Bearer ${authToken}`)
        .expect(404); // Should return 404, not 401 to avoid user enumeration
    });

    it('should enforce role-based access control', async () => {
      // Regular user should not be able to access admin endpoints
      await request(app)
        .get('/api/admin/users')
        .set('Authorization', `Bearer ${authToken}`)
        .expect(403);

      // Admin user should be able to access admin endpoints
      await request(app)
        .get('/api/admin/users')
        .set('Authorization', `Bearer ${adminToken}`)
        .expect(200);
    });

    it('should prevent privilege escalation', async () => {
      // Try to access admin functions with regular user token
      await request(app)
        .post('/api/admin/users/123/role')
        .set('Authorization', `Bearer ${authToken}`)
        .send({ role: 'admin' })
        .expect(403);
    });
  });

  describe('Input Validation Security', () => {
    it('should prevent XSS in workflow names', async () => {
      const xssPayloads = [
        '<script>alert("xss")</script>',
        'javascript:alert("xss")',
        '<img src="x" onerror="alert(1)">',
        '"><script>alert("xss")</script>',
        "'; DROP TABLE workflows; --"
      ];

      for (const payload of xssPayloads) {
        const response = await request(app)
          .post('/api/workflows')
          .set('Authorization', `Bearer ${authToken}`)
          .send({
            name: payload,
            description: 'Test workflow',
            triggers: [{ type: 'manual' }],
            actions: [{ type: 'api_call', config: { url: 'https://example.com' } }]
          })
          .expect(400);

        expect(response.body.success).toBe(false);
        expect(response.body.error).toContain('validation');
      }
    });

    it('should prevent command injection in API calls', async () => {
      const commandInjectionPayloads = [
        '; ls -la',
        '&& cat /etc/passwd',
        '| whoami',
        '`id`',
        '$(whoami)'
      ];

      for (const payload of commandInjectionPayloads) {
        const response = await request(app)
          .post('/api/workflows')
          .set('Authorization', `Bearer ${authToken}`)
          .send({
            name: 'Test Workflow',
            description: 'Test workflow',
            triggers: [{ type: 'webhook' }],
            actions: [
              {
                type: 'api_call',
                config: {
                  url: `https://example.com/${payload}`,
                  method: 'GET'
                }
              }
            ]
          })
          .expect(400);

        expect(response.body.success).toBe(false);
      }
    });

    it('should validate file upload security', async () => {
      // Test malicious file upload
      const maliciousFile = {
        filename: '../../../etc/passwd',
        content: 'malicious content'
      };

      // This would be a file upload test if implemented
      // For now, we test the file path validation
      expect(maliciousFile.filename).toContain('..');
    });

    it('should prevent path traversal attacks', async () => {
      const pathTraversalPayloads = [
        '../../../etc/passwd',
        '..\\..\\..\\windows\\system32\\drivers\\etc\\hosts',
        '....//....//....//etc//passwd',
        '%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd'
      ];

      for (const payload of pathTraversalPayloads) {
        const response = await request(app)
          .get(`/api/files/${payload}`)
          .set('Authorization', `Bearer ${authToken}`)
          .expect(400);

        expect(response.body.success).toBe(false);
      }
    });
  });

  describe('Data Protection Security', () => {
    it('should encrypt sensitive data at rest', async () => {
      // This would test actual database encryption
      // For now, we test that sensitive fields are not returned in responses
      const response = await request(app)
        .post('/api/workflows')
        .set('Authorization', `Bearer ${authToken}`)
        .send({
          name: 'Test Workflow with Secret',
          description: 'Test workflow',
          triggers: [{ type: 'manual' }],
          actions: [
            {
              type: 'api_call',
              config: {
                url: 'https://example.com',
                method: 'POST',
                headers: {
                  'Authorization': 'Bearer secret-token'
                }
              }
            }
          ]
        });

      // The response should not contain the secret token in plain text
      const responseText = JSON.stringify(response.body);
      expect(responseText).not.toContain('secret-token');
    });

    it('should use secure transmission protocols', async () => {
      // Test that API is only accessible over HTTPS (in production)
      if (process.env.NODE_ENV === 'production') {
        await request('http://silhouette-workflow.com')
          .get('/api/health')
          .expect(301); // Should redirect to HTTPS
      }
    });

    it('should implement proper data validation', async () => {
      // Test with missing required fields
      await request(app)
        .post('/api/workflows')
        .set('Authorization', `Bearer ${authToken}`)
        .send({
          name: '', // Empty name should fail
          description: 'Test workflow',
          triggers: [],
          actions: []
        })
        .expect(400);

      // Test with invalid data types
      await request(app)
        .post('/api/workflows')
        .set('Authorization', `Bearer ${authToken}`)
        .send({
          name: 'Test Workflow',
          description: 'Test workflow',
          triggers: 'invalid', // Should be array
          actions: 123 // Should be array
        })
        .expect(400);
    });
  });

  describe('API Security', () => {
    it('should implement rate limiting', async () => {
      const requests = Array(101).fill(null).map(() => 
        request(app)
          .get('/api/workflows')
          .set('Authorization', `Bearer ${authToken}`)
      );

      const responses = await Promise.all(requests);
      const lastResponse = responses[responses.length - 1];
      
      // After 100 requests, should get rate limited
      expect([429, 503]).toContain(lastResponse.status);
    });

    it('should validate API request size', async () => {
      const largePayload = {
        name: 'A'.repeat(1000000), // 1MB name
        description: 'Test workflow',
        triggers: [{ type: 'manual' }],
        actions: [{ type: 'api_call', config: { url: 'https://example.com' } }]
      };

      await request(app)
        .post('/api/workflows')
        .set('Authorization', `Bearer ${authToken}`)
        .send(largePayload)
        .expect(413); // Payload too large
    });

    it('should sanitize API responses', async () => {
      const response = await request(app)
        .post('/api/workflows')
        .set('Authorization', `Bearer ${authToken}`)
        .send({
          name: 'Test <script>alert("xss")</script> Workflow',
          description: 'Test workflow',
          triggers: [{ type: 'manual' }],
          actions: [{ type: 'api_call', config: { url: 'https://example.com' } }]
        });

      // Response should sanitize the script tag
      expect(response.body.data.name).not.toContain('<script>');
      expect(response.body.data.name).toContain('&lt;script&gt;');
    });

    it('should implement proper CORS headers', async () => {
      const response = await request(app)
        .options('/api/workflows')
        .set('Origin', 'https://malicious-site.com')
        .set('Access-Control-Request-Method', 'POST');

      const corsHeader = response.headers['access-control-allow-origin'];
      expect(corsHeader).not.toBe('*');
      expect(corsHeader).not.toBe('https://malicious-site.com');
    });
  });

  describe('Error Handling Security', () => {
    it('should not expose stack traces in production', async () => {
      if (process.env.NODE_ENV === 'production') {
        // Trigger an internal error
        await request(app)
          .get('/api/nonexistent-endpoint')
          .expect(404);

        // This test would need to be more specific based on actual error handling
        // The key is that production should not expose detailed error information
      }
    });

    it('should handle 404 errors without information leakage', async () => {
      const response = await request(app)
        .get('/api/nonexistent-resource/12345')
        .expect(404);

      expect(response.body.error).not.toContain('database');
      expect(response.body.error).not.toContain('sql');
      expect(response.body.error).toContain('Not found');
    });
  });
});
```

## 3. Dependency Security Scanning

### Snyk Configuration

```json
// .snyk
{
  "version": "v1.25.0",
  "language-settings": {
    "JAVASCRIPT": {
      "packageManager": "npm"
    }
  },
  "exclude": {
    "global": [
      "**/test/**",
      "**/tests/**",
      "**/node_modules/**",
      "**/bower_components/**",
      "**/.git/**",
      "**/.svn/**",
      "**/.hg/**",
      "**/.DS_Store/**",
      "**/.idea/**",
      "**/.vscode/**",
      "**/*.iml",
      "**/*.log",
      "**/coverage/**",
      "**/dist/**",
      "**/build/**"
    ]
  },
  "rule": {
    "vulnerability": {
      "severity-threshold": "high"
    },
    "license": {
      "severity-threshold": "high"
    }
  },
  "ignore": {
    "SNYK-JS-LODASH-567746": {
      "reason": "Only affects lodash templates, not the core library",
      "expires": "2025-12-31T23:59:59.999Z"
    },
    "SNYK-JS-JQUERY-565129": {
      "reason": "jQuery is used in a sandboxed environment",
      "expires": "2025-12-31T23:59:59.999Z"
    }
  },
  "monitor": {
    "projectName": "silhouette-workflow-security",
    "projectId": "silhouette-workflow-123"
  }
}
```

### npm Audit Automation

```bash
#!/bin/bash
# scripts/dependency-security-audit.sh

set -e

echo "ğŸ” Starting dependency security audit..."

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Function to check if a package.json exists
check_package_json() {
    if [ ! -f "package.json" ]; then
        echo -e "${RED}âŒ package.json not found in $(pwd)${NC}"
        return 1
    fi
    return 0
}

# Function to install dependencies if node_modules doesn't exist
ensure_dependencies() {
    if [ ! -d "node_modules" ]; then
        echo "ğŸ“¦ Installing dependencies..."
        npm install --audit=false
    fi
}

# Function to run npm audit
run_npm_audit() {
    echo "ğŸ” Running npm audit..."
    
    # Run npm audit
    npm audit --json > audit-report.json 2>&1 || true
    
    # Parse audit results
    if [ -f "audit-report.json" ]; then
        local high_vulns=$(jq '.metadata.vulnerabilities.high // 0' audit-report.json)
        local critical_vulns=$(jq '.metadata.vulnerabilities.critical // 0' audit-report.json)
        local moderate_vulns=$(jq '.metadata.vulnerabilities.moderate // 0' audit-report.json)
        local low_vulns=$(jq '.metadata.vulnerabilities.low // 0' audit-report.json)
        
        echo ""
        echo "ğŸ“Š Audit Summary:"
        echo "   Critical: $critical_vulns"
        echo "   High: $high_vulns"
        echo "   Moderate: $moderate_vulns"
        echo "   Low: $low_vulns"
        echo ""
        
        # Fail if critical or high vulnerabilities found
        if [ "$critical_vulns" -gt 0 ] || [ "$high_vulns" -gt 0 ]; then
            echo -e "${RED}âŒ Critical or high vulnerabilities found!${NC}"
            
            # Get list of vulnerable packages
            echo ""
            echo "ğŸ” Vulnerable packages:"
            jq -r '.vulnerabilities | to_entries[] | "\(.key): \(.value.severity)"' audit-report.json | head -20
            
            return 1
        else
            echo -e "${GREEN}âœ… No critical or high vulnerabilities found${NC}"
        fi
    else
        echo -e "${YELLOW}âš ï¸  Audit report not generated${NC}"
        return 1
    fi
}

# Function to run Snyk scan
run_snyk_scan() {
    if command -v snyk &> /dev/null; then
        echo "ğŸ” Running Snyk scan..."
        
        # Test for vulnerabilities
        snyk test --json --severity-threshold=high > snyk-report.json 2>&1 || true
        
        if [ -f "snyk-report.json" ]; then
            local snyk_vulns=$(jq '.vulnerabilities | length' snyk-report.json 2>/dev/null || echo "0")
            
            echo ""
            echo "ğŸ“Š Snyk Summary:"
            echo "   Total vulnerabilities: $snyk_vulns"
            echo ""
            
            if [ "$snyk_vulns" -gt 0 ]; then
                echo -e "${YELLOW}âš ï¸  Snyk found vulnerabilities${NC}"
                jq -r '.vulnerabilities[] | "   \(.title) in \(.packageName)@\(..packageVersion)"' snyk-report.json | head -10
            else
                echo -e "${GREEN}âœ… No vulnerabilities found by Snyk${NC}"
            fi
        fi
    else
        echo -e "${YELLOW}âš ï¸  Snyk CLI not installed, skipping Snyk scan${NC}"
    fi
}

# Function to check outdated packages
check_outdated_packages() {
    echo "ğŸ“… Checking for outdated packages..."
    
    local outdated=$(npm outdated --json 2>/dev/null || echo '{}')
    
    if [ "$outdated" != "{}" ]; then
        echo -e "${YELLOW}âš ï¸  Some packages are outdated:${NC}"
        echo "$outdated" | jq -r 'to_entries[] | "   \(.key): current \(.value.current) -> latest \(.value.latest)"' | head -10
    else
        echo -e "${GREEN}âœ… All packages are up to date${NC}"
    fi
}

# Function to check licenses
check_licenses() {
    echo "ğŸ“‹ Checking package licenses..."
    
    if command -v nlf &> /dev/null; then
        nlf --summary detail > license-report.txt 2>&1 || true
        
        if [ -f "license-report.txt" ]; then
            echo ""
            echo "ğŸ“Š License Summary:"
            tail -20 license-report.txt
        fi
    else
        echo -e "${YELLOW}âš ï¸  nlf not installed, skipping license check${NC}"
    fi
}

# Function to generate remediation report
generate_remediation_report() {
    echo "ğŸ“ Generating remediation report..."
    
    {
        echo "# Security Audit Report"
        echo "Generated: $(date)"
        echo ""
        
        if [ -f "audit-report.json" ]; then
            echo "## NPM Audit Results"
            jq -r '.metadata | "Total dependencies: \(.totalDependencies)\nVulnerable dependencies: \(..vulnerableDependencies)"' audit-report.json
            echo ""
        fi
        
        if [ -f "snyk-report.json" ]; then
            echo "## Snyk Results"
            jq -r '.vulnerabilities[] | "- \(.title) in \(.packageName)@\(.packageVersion) (\(.severity))"' snyk-report.json | head -20
            echo ""
        fi
        
        echo "## Recommendations"
        echo "1. Update all packages to latest secure versions"
        echo "2. Remove unused dependencies"
        echo "3. Regular security audits in CI/CD pipeline"
        echo "4. Monitor security advisories for critical dependencies"
        
    } > security-audit-report.md
    
    echo -e "${GREEN}ğŸ“ Security audit report saved to: security-audit-report.md${NC}"
}

# Main execution
main() {
    local dirs=("backend" "frontend" "mobile")
    local failed_dirs=()
    
    for dir in "${dirs[@]}"; do
        if [ -d "$dir" ]; then
            echo ""
            echo "ğŸ” Checking directory: $dir"
            echo "================================"
            
            cd "$dir"
            
            if check_package_json && ensure_dependencies; then
                if ! run_npm_audit; then
                    failed_dirs+=("$dir")
                fi
                
                run_snyk_scan
                check_outdated_packages
                check_licenses
            fi
            
            cd ..
        fi
    done
    
    # Generate overall report
    generate_remediation_report
    
    # Final summary
    echo ""
    echo "ğŸ” Security Audit Complete"
    echo "=========================="
    
    if [ ${#failed_dirs[@]} -eq 0 ]; then
        echo -e "${GREEN}âœ… All directories passed security audit${NC}"
        exit 0
    else
        echo -e "${RED}âŒ Security issues found in:${NC}"
        for dir in "${failed_dirs[@]}"; do
            echo "   - $dir"
        done
        echo ""
        echo "Please review the security-audit-report.md for remediation steps"
        exit 1
    fi
}

# Run main function
main "$@"
```

### Container Security Scanning

```dockerfile
# security-tests/Dockerfile.trivy
FROM aquasec/trivy:latest AS security-scanner

WORKDIR /workspace
COPY . /workspace

# Install dependencies
RUN apk add --no-cache jq

# Copy scripts
COPY scripts/container-security-scan.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/container-security-scan.sh

CMD ["/usr/local/bin/container-security-scan.sh"]
```

```bash
#!/bin/bash
# scripts/container-security-scan.sh

set -e

echo "ğŸ” Starting container security scan..."

# Configuration
IMAGE_NAME="${IMAGE_NAME:-ghcr.io/silhouette/workflow-backend:latest}"
OUTPUT_DIR="${OUTPUT_DIR:-./security-reports}"
SCAN_FORMAT="${SCAN_FORMAT:-sarif}"

# Create output directory
mkdir -p "$OUTPUT_DIR"

# Function to run Trivy scan
run_trivy_scan() {
    local scan_type="$1"
    local output_file="$2"
    
    echo "ğŸ” Running Trivy $scan_type scan on $IMAGE_NAME"
    
    case "$scan_type" in
        "vulnerability")
            trivy image --format "$SCAN_FORMAT" --output "$output_file" "$IMAGE_NAME"
            ;;
        "config")
            trivy config --format "$SCAN_FORMAT" --output "$output_file" "$IMAGE_NAME"
            ;;
        "secret")
            trivy fs --format "$SCAN_FORMAT" --output "$output_file" /workspace
            ;;
        *)
            echo "âŒ Unknown scan type: $scan_type"
            return 1
            ;;
    esac
}

# Function to run Docker Scout scan
run_docker_scout_scan() {
    local output_file="$1"
    
    if command -v docker &> /dev/null; then
        echo "ğŸ” Running Docker Scout scan on $IMAGE_NAME"
        
        # Install Docker Scout CLI if not available
        if ! command -v docker scout &> /dev/null; then
            echo "Installing Docker Scout CLI..."
            curl -sSfL https://raw.githubusercontent.com/docker/scout-cli/main/install.sh | sh -s -- -b /usr/local/bin
        fi
        
        # Run Docker Scout scan
        docker scout cves --format json --output "$output_file" "$IMAGE_NAME" || true
    else
        echo "âš ï¸  Docker not available, skipping Docker Scout scan"
    fi
}

# Function to check container best practices
check_container_best_practices() {
    echo "ğŸ” Checking container best practices..."
    
    # Check if running as non-root user
    echo "Checking for non-root user..."
    if docker run --rm "$IMAGE_NAME" id -u 2>/dev/null | grep -q '^0$'; then
        echo "âŒ Container is running as root user"
    else
        echo "âœ… Container is not running as root user"
    fi
    
    # Check for secure base image
    echo "Checking base image..."
    docker inspect "$IMAGE_NAME" --format='{{.Config.Image}}' | grep -E '(alpine|debian|ubuntu|slim)' > /dev/null && \
        echo "âœ… Using secure base image" || \
        echo "âš ï¸  Non-standard base image detected"
    
    # Check for latest tag (should be avoided in production)
    echo "Checking image tag..."
    echo "$IMAGE_NAME" | grep -q ':latest$' && \
        echo "âš ï¸  Using 'latest' tag (not recommended for production)" || \
        echo "âœ… Using specific image tag"
}

# Main execution
main() {
    echo "ğŸ” Container Security Scan for: $IMAGE_NAME"
    echo "============================================"
    
    # Run Trivy vulnerability scan
    run_trivy_scan "vulnerability" "$OUTPUT_DIR/trivy-vulnerabilities.$SCAN_FORMAT"
    
    # Run Trivy configuration scan
    run_trivy_scan "config" "$OUTPUT_DIR/trivy-config.$SCAN_FORMAT"
    
    # Run Trivy secret scan
    run_trivy_scan "secret" "$OUTPUT_DIR/trivy-secrets.$SCAN_FORMAT"
    
    # Run Docker Scout scan
    run_docker_scout_scan "$OUTPUT_DIR/docker-scout-cves.json"
    
    # Check container best practices
    check_container_best_practices
    
    # Generate summary report
    echo ""
    echo "ğŸ“ Generating security summary..."
    
    {
        echo "# Container Security Scan Report"
        echo "Generated: $(date)"
        echo "Image: $IMAGE_NAME"
        echo ""
        
        # Trivy vulnerability summary
        if [ -f "$OUTPUT_DIR/trivy-vulnerabilities.sarif" ]; then
            echo "## Trivy Vulnerability Scan"
            local high_vulns=$(jq '[.runs[0].results[] | select(.properties.severity == "HIGH" or .properties.severity == "CRITICAL")] | length' "$OUTPUT_DIR/trivy-vulnerabilities.sarif")
            local medium_vulns=$(jq '[.runs[0].results[] | select(.properties.severity == "MEDIUM")] | length' "$OUTPUT_DIR/trivy-vulnerabilities.sarif")
            echo "- High/Critical vulnerabilities: $high_vulns"
            echo "- Medium vulnerabilities: $medium_vulns"
            echo ""
        fi
        
        # Docker Scout summary
        if [ -f "$OUTPUT_DIR/docker-scout-cves.json" ]; then
            echo "## Docker Scout Results"
            local cves=$(jq '.vulnerabilities | length' "$OUTPUT_DIR/docker-scout-cves.json" 2>/dev/null || echo "0")
            echo "- Total CVEs: $cves"
            echo ""
        fi
        
        echo "## Recommendations"
        echo "1. Regular security scanning in CI/CD pipeline"
        echo "2. Use minimal base images (alpine, distroless)"
        echo "3. Run containers as non-root user"
        echo "4. Scan dependencies for known vulnerabilities"
        echo "5. Implement runtime security monitoring"
        
    } > "$OUTPUT_DIR/security-summary.md"
    
    echo ""
    echo "ğŸ” Container Security Scan Complete"
    echo "==================================="
    echo "ğŸ“‚ Reports saved to: $OUTPUT_DIR"
    echo "ğŸ“ Summary: $OUTPUT_DIR/security-summary.md"
}

# Run main function
main "$@"
```

## 4. Infrastructure Security Testing

### Kubernetes Security Scan

```yaml
# security-tests/kubernetes-security-scan.yml
apiVersion: batch/v1
kind: Job
metadata:
  name: kubernetes-security-scan
  namespace: security-testing
spec:
  template:
    spec:
      serviceAccountName: security-scanner
      containers:
      - name: kube-bench
        image: aquasec/kube-bench:latest
        command: ["kube-bench", "node", "--json"]
        volumeMounts:
        - name: kubeconfig
          mountPath: /root/.kube
          readOnly: true
      - name: kube-hunter
        image: aquasec/kube-hunter:latest
        command: ["kube-hunter", "--pod", "--json"]
        env:
        - name: KUBERNETES_SERVICE_HOST
          value: "kubernetes.default.svc"
        - name: KUBERNETES_SERVICE_PORT
          value: "443"
      volumes:
      - name: kubeconfig
        configMap:
          name: kubeconfig
  backoffLimit: 1
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: security-scanner
  namespace: security-testing
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: security-testing
  name: security-scanner-role
rules:
- apiGroups: [""]
  resources: ["*"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["apps"]
  resources: ["*"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["rbac.authorization.k8s.io"]
  resources: ["*"]
  verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: security-scanner-binding
  namespace: security-testing
subjects:
- kind: ServiceAccount
  name: security-scanner
  namespace: security-testing
roleRef:
  kind: Role
  name: security-scanner-role
  apiGroup: rbac.authorization.k8s.io
```

### Terraform Security Analysis

```bash
#!/bin/bash
# scripts/terraform-security-scan.sh

set -e

echo "ğŸ” Starting Terraform security scan..."

# Configuration
TERRAFORM_DIR="${TERRAFORM_DIR:-./config/terraform}"
OUTPUT_DIR="${OUTPUT_DIR:-./security-reports}"

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

# Function to install tools
install_tools() {
    echo "ğŸ”§ Installing security scanning tools..."
    
    # Install tfsec
    if ! command -v tfsec &> /dev/null; then
        echo "Installing tfsec..."
        curl -s https://raw.githubusercontent.com/aquasecurity/tfsec/master/scripts/install_linux.sh | bash
    fi
    
    # Install Checkov
    if ! command -v checkov &> /dev/null; then
        echo "Installing Checkov..."
        pip install checkov
    fi
    
    # Install Terrascan
    if ! command -v terrascan &> /dev/null; then
        echo "Installing Terrascan..."
        curl -L https://github.com/accurics/terrascan/releases/latest/download/terrascan_Linux_x86_64.tar.gz | tar xz
        sudo mv terrascan /usr/local/bin/
    fi
}

# Function to run tfsec
run_tfsec() {
    echo "ğŸ” Running tfsec security scan..."
    
    cd "$TERRAFORM_DIR"
    
    tfsec . --format json --out "$OUTPUT_DIR/tfsec-report.json" || true
    tfsec . --format sarif --out "$OUTPUT_DIR/tfsec-report.sarif" || true
    
    if [ -f "$OUTPUT_DIR/tfsec-report.json" ]; then
        local critical_issues=$(jq '[.results[] | select(.severity == "CRITICAL")] | length' "$OUTPUT_DIR/tfsec-report.json")
        local high_issues=$(jq '[.results[] | select(.severity == "HIGH")] | length' "$OUTPUT_DIR/tfsec-report.json")
        
        echo ""
        echo "ğŸ“Š tfsec Summary:"
        echo "   Critical: $critical_issues"
        echo "   High: $high_issues"
        
        if [ "$critical_issues" -gt 0 ] || [ "$high_issues" -gt 0 ]; then
            echo -e "${RED}âŒ Critical or high security issues found${NC}"
            return 1
        else
            echo -e "${GREEN}âœ… No critical or high issues found${NC}"
        fi
    fi
    
    cd - > /dev/null
}

# Function to run Checkov
run_checkov() {
    echo "ğŸ” Running Checkov security scan..."
    
    checkov -d "$TERRAFORM_DIR" \
            --framework terraform \
            --output json \
            --output-file "$OUTPUT_DIR/checkov-report.json" \
            --skip-check CKV_*,BC_* || true
    
    if [ -f "$OUTPUT_DIR/checkov-report.json" ]; then
        local failed_checks=$(jq '[.results.failed_checks[] | select(.check_severity in ["HIGH", "CRITICAL"])] | length' "$OUTPUT_DIR/checkov-report.json")
        
        echo ""
        echo "ğŸ“Š Checkov Summary:"
        echo "   Failed checks (High/Critical): $failed_checks"
        
        if [ "$failed_checks" -gt 0 ]; then
            echo -e "${YELLOW}âš ï¸  Some security checks failed${NC}"
        else
            echo -e "${GREEN}âœ… All security checks passed${NC}"
        fi
    fi
}

# Function to run Terrascan
run_terrascan() {
    echo "ğŸ” Running Terrascan security scan..."
    
    terrascan scan -d "$TERRAFORM_DIR" \
                   -o json \
                   -f "$OUTPUT_DIR/terrascan-report.json" || true
    
    if [ -f "$OUTPUT_DIR/terrascan-report.json" ]; then
        local high_violations=$(jq '[.results.violations[] | select(.severity == "HIGH")] | length' "$OUTPUT_DIR/terrascan-report.json")
        local critical_violations=$(jq '[.results.violations[] | select(.severity == "CRITICAL")] | length' "$OUTPUT_DIR/terrascan-report.json")
        
        echo ""
        echo "ğŸ“Š Terrascan Summary:"
        echo "   Critical: $critical_violations"
        echo "   High: $high_violations"
        
        if [ "$critical_violations" -gt 0 ] || [ "$high_violations" -gt 0 ]; then
            echo -e "${RED}âŒ Critical or high violations found${NC}"
            return 1
        else
            echo -e "${GREEN}âœ… No critical or high violations found${NC}"
        fi
    fi
}

# Function to check infrastructure best practices
check_infrastructure_best_practices() {
    echo "ğŸ” Checking infrastructure best practices..."
    
    local issues=0
    
    # Check for public S3 buckets
    if grep -r "acl.*public" "$TERRAFORM_DIR" 2>/dev/null; then
        echo "âŒ Public S3 bucket ACLs detected"
        ((issues++))
    fi
    
    # Check for unencrypted volumes
    if grep -r "encrypted.*false" "$TERRAFORM_DIR" 2>/dev/null; then
        echo "âŒ Unencrypted volumes detected"
        ((issues++))
    fi
    
    # Check for default security groups
    if grep -r "security_group_id.*sg-default" "$TERRAFORM_DIR" 2>/dev/null; then
        echo "âš ï¸  Default security groups detected"
    fi
    
    # Check for debug logging in production
    if grep -r "debug.*true" "$TERRAFORM_DIR" 2>/dev/null | grep -v dev; then
        echo "âŒ Debug logging enabled in production"
        ((issues++))
    fi
    
    # Check for resource tagging
    if ! grep -r "tags.*Name" "$TERRAFORM_DIR" 2>/dev/null; then
        echo "âš ï¸  Missing resource tagging"
    fi
    
    if [ "$issues" -eq 0 ]; then
        echo -e "${GREEN}âœ… No major infrastructure issues detected${NC}"
    else
        echo -e "${RED}âŒ $issues infrastructure issues detected${NC}"
        return 1
    fi
}

# Function to generate infrastructure security report
generate_infrastructure_report() {
    echo "ğŸ“ Generating infrastructure security report..."
    
    {
        echo "# Infrastructure Security Report"
        echo "Generated: $(date)"
        echo "Directory: $TERRAFORM_DIR"
        echo ""
        
        if [ -f "$OUTPUT_DIR/tfsec-report.json" ]; then
            echo "## tfsec Results"
            jq -r '.results[] | "- \(.severity): \(.short_description)"' "$OUTPUT_DIR/tfsec-report.json" | head -20
            echo ""
        fi
        
        if [ -f "$OUTPUT_DIR/terrascan-report.json" ]; then
            echo "## Terrascan Results"
            jq -r '.results.violations[] | "- \(.severity): \(.description)"' "$OUTPUT_DIR/terrascan-report.json" | head -20
            echo ""
        fi
        
        echo "## Infrastructure Best Practices"
        echo "1. Use encryption at rest for all storage resources"
        echo "2. Implement network segmentation with security groups"
        echo "3. Enable logging and monitoring for all resources"
        echo "4. Use least privilege access for service accounts"
        echo "5. Implement proper backup and disaster recovery"
        
    } > "$OUTPUT_DIR/infrastructure-security-report.md"
    
    echo -e "${GREEN}ğŸ“ Infrastructure security report saved to: $OUTPUT_DIR/infrastructure-security-report.md${NC}"
}

# Main execution
main() {
    # Create output directory
    mkdir -p "$OUTPUT_DIR"
    
    # Install tools
    install_tools
    
    echo "ğŸ” Infrastructure Security Scan"
    echo "==============================="
    
    # Run security scans
    run_tfsec
    run_checkov
    run_terrascan
    check_infrastructure_best_practices
    
    # Generate report
    generate_infrastructure_report
    
    echo ""
    echo "ğŸ” Infrastructure Security Scan Complete"
    echo "======================================="
    echo "ğŸ“‚ Reports saved to: $OUTPUT_DIR"
    echo "ğŸ“ Summary: $OUTPUT_DIR/infrastructure-security-report.md"
}

# Run main function
main "$@"
```

## 5. Security Testing en CI/CD

### GitHub Actions Security Workflow

```yaml
# .github/workflows/security-testing.yml
name: Security Testing

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    - cron: '0 6 * * *'  # Daily at 6 AM
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Job 1: SAST - Static Application Security Testing
  sast:
    name: SAST Security Analysis
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for analysis

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run ESLint security rules
        run: |
          npm install -g @typescript-eslint/parser @typescript-eslint/eslint-plugin
          npx eslint . --ext .ts,.js --format json --output-file eslint-security-report.json || true

      - name: Run Semgrep security scan
        uses: returntocorp/semgrep-action@v1
        with:
          config: >-
            p/security-audit
            p/secrets
            p/owasp-top-ten
          generateSarif: "1"
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}

      - name: Upload Semgrep results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: semgrep.sarif

      - name: Run SonarQube Security Scan
        uses: sonarqube-quality-gate-action@master
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}

      - name: Run CodeQL Analysis
        uses: github/codeql-action/analyze@v2
        with:
          languages: javascript,typescript
          queries: security-extended,security-and-quality

      - name: Upload security artifacts
        uses: actions/upload-artifact@v3
        with:
          name: sast-reports
          path: |
            eslint-security-report.json
            semgrep.sarif

  # Job 2: Dependency Security Scanning
  dependency-scan:
    name: Dependency Security Scanning
    runs-on: ubuntu-latest
    strategy:
      matrix:
        directory: [backend, frontend, mobile]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install dependencies
        working-directory: ${{ matrix.directory }}
        run: npm ci

      - name: Run npm audit
        working-directory: ${{ matrix.directory }}
        run: |
          npm audit --json > ../npm-audit-${{ matrix.directory }}.json || true
          npm audit

      - name: Run Snyk security scan
        uses: snyk/actions/node@master
        working-directory: ${{ matrix.directory }}
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high --json --file=package.json

      - name: Upload dependency scan results
        uses: actions/upload-artifact@v3
        with:
          name: dependency-reports-${{ matrix.directory }}
          path: npm-audit-${{ matrix.directory }}.json

  # Job 3: Container Security Scanning
  container-scan:
    name: Container Security Scanning
    runs-on: ubuntu-latest
    needs: [build-images]
    if: github.event_name == 'push'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Log in to Container Registry
        uses: docker/login-action@v2
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and export Docker image
        uses: docker/build-push-action@v4
        with:
          context: ./backend
          file: ./backend/Dockerfile
          outputs: type=docker,dest=/tmp/backend-image.tar

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'backend:latest'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Run Anchore Grype scanner
        uses: anchore/scan-action@v3
        with:
          image: 'backend:latest'
          output-format: sarif
          output-file-path: grype-results.sarif

      - name: Upload Grype scan results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: grype-results.sarif

  # Job 4: DAST - Dynamic Application Security Testing
  dast:
    name: DAST Security Testing
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Start application
        run: |
          docker-compose up -d
          timeout 60 bash -c 'until curl -f http://localhost:3000; do sleep 5; done'

      - name: Run OWASP ZAP Baseline Scan
        uses: zaproxy/action-baseline@v0.7.0
        with:
          target: 'http://localhost:3000'
          rules_file_name: '.zap/zap-baseline-scan.yml'
          cmd_options: '-a'

      - name: Run OWASP ZAP Full Scan
        uses: zaproxy/action-full-scan@v0.4.0
        with:
          target: 'http://localhost:3000'
          rules_file_name: '.zap/zap-full-scan.yml'
          cmd_options: '-a'

      - name: Run custom security tests
        working-directory: security-tests
        run: |
          npm install
          npm test

  # Job 5: Infrastructure Security Scanning
  infrastructure-scan:
    name: Infrastructure Security Scanning
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0

      - name: Run tfsec security scan
        uses: aquasecurity/tfsec-action@v1.0.2
        with:
          format: json
          output_file_path: tfsec-results.json
          working_directory: config/terraform

      - name: Run Checkov security scan
        uses: bridgecrewio/checkov-action@master
        with:
          directory: config/terraform
          framework: terraform
          output_format: json
          output_file_path: checkov-results.json

      - name: Run Terrascan security scan
        uses: accurics/terrascan-action@v1
        with:
          iac_type: terraform
          iac_dir: config/terraform
          policy_type: aws
          output_format: json
          output_file_path: terrascan-results.json

  # Job 6: Kubernetes Security Scanning
  kubernetes-scan:
    name: Kubernetes Security Scanning
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'

      - name: Configure kubectl
        run: |
          echo "${{ secrets.KUBE_CONFIG }}" | base64 -d > kubeconfig
          export KUBECONFIG=kubeconfig

      - name: Run kube-bench security scan
        run: |
          export KUBECONFIG=kubeconfig
          kubectl run kube-bench --image=aquasec/kube-bench:latest --rm -it -- sh -c \
          "kube-bench node --json > kube-bench-results.json"

      - name: Run kube-hunter security scan
        run: |
          export KUBECONFIG=kubeconfig
          kubectl run kube-hunter --image=aquasec/kube-hunter:latest --rm -it -- sh -c \
          "kube-hunter --pod --json > kube-hunter-results.json"

      - name: Upload k8s security results
        uses: actions/upload-artifact@v3
        with:
          name: kubernetes-security-reports
          path: |
            kube-bench-results.json
            kube-hunter-results.json

  # Job 7: Security Compliance Check
  compliance-check:
    name: Security Compliance Check
    runs-on: ubuntu-latest
    needs: [sast, dependency-scan, container-scan, dast, infrastructure-scan]
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v3

      - name: Aggregate security results
        run: |
          node scripts/aggregate-security-results.js > security-summary.json || echo '{"overall":"failed"}' > security-summary.json

      - name: Check security gates
        run: |
          node scripts/check-security-gates.js security-summary.json

      - name: Generate security report
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = JSON.parse(fs.readFile('security-summary.json', 'utf8'));
            
            const comment = report.overall === 'passed' ? 
              'âœ… **Security Testing Passed**' : 
              'âŒ **Security Testing Failed**';
            
            const details = report.issues ? 
              `### Security Issues Found\n${report.issues.map(issue => `- ${issue}`).join('\n')}` :
              '### âœ… No security issues found';
            
            const body = `${comment}\n\n${details}\n\n### ğŸ“Š Security Test Results\n- SAST: ${report.sast || 'N/A'}\n- Dependencies: ${report.dependencies || 'N/A'}\n- Container: ${report.container || 'N/A'}\n- DAST: ${report.dast || 'N/A'}\n- Infrastructure: ${report.infrastructure || 'N/A'}`;
            
            if (context.eventName === 'pull_request') {
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
            }

      - name: Upload security summary
        uses: actions/upload-artifact@v3
        with:
          name: security-summary
          path: security-summary.json
```

## ConclusiÃ³n

El **Security Testing Framework** de Silhouette Workflow Creation proporciona una cobertura integral de testing de seguridad que garantiza que la plataforma estÃ© protegida contra todas las amenazas conocidas. Con SAST, DAST, dependency scanning, container security, infrastructure security y compliance testing, este framework establece un estÃ¡ndar de seguridad de clase empresarial.

### Beneficios Principales

1. **Cobertura Completa**: SAST, DAST, IAST, dependency, container e infrastructure scanning
2. **Herramientas MÃºltiples**: SonarQube, OWASP ZAP, Snyk, Trivy, tfsec, Checkov
3. **IntegraciÃ³n CI/CD**: Testing automatizado en cada push y PR
4. **Compliance AutomÃ¡tico**: SOX, GDPR, ISO 27001, SOC 2 compliance checking
5. **Threat Modeling**: AnÃ¡lisis proactivo de vectores de ataque
6. **Real-time Monitoring**: Alertas automÃ¡ticas de vulnerabilidades
7. **Reportes AutomÃ¡ticos**: GeneraciÃ³n automÃ¡tica de reportes de seguridad

### MÃ©tricas de Ã‰xito

- **Security Scan Coverage**: 100% de componentes escaneados
- **Vulnerability Detection**: 0 crÃ­ticas, <5 menores
- **False Positive Rate**: <5%
- **Compliance Score**: 100% en todos los frameworks
- **Time to Detection**: <1 hora para vulnerabilidades crÃ­ticas
- **Remediation Time**: <24 horas para vulnerabilidades crÃ­ticas

---

**Autor**: Silhouette Anonimo  
**VersiÃ³n**: 1.0.0  
**Fecha**: 2025-11-09  
**Estado**: ImplementaciÃ³n Completa