/**
 * Framework Silhouette Enterprise V4.0 - Auto Optimizer
 * 
 * Sistema de optimizaci√≥n autom√°tica basado en ML que mejora continuamente
 * el rendimiento del framework mediante an√°lisis de patrones, predicciones
 * y ajustes autom√°ticos de par√°metros.
 * 
 * Autor: Silhouette Anonimo
 * Versi√≥n: 4.0.0
 * Fecha: 2025-11-09
 */

import { getFrameworkConfig, optimizationConfig } from '../config';
import { getCoordinator } from '../coordinator';
import { getWorkflowEngine } from '../workflow';
import { getAudioVisualSystem } from '../audiovisual';

interface OptimizationMetrics {
  timestamp: Date;
  performance: {
    responseTime: number;
    throughput: number;
    cpuUsage: number;
    memoryUsage: number;
    diskUsage: number;
    networkLatency: number;
  };
  quality: {
    overall: number;
    byComponent: { [key: string]: number };
    trends: { [key: string]: number[] };
  };
  resourceUtilization: {
    cpu: number;
    memory: number;
    storage: number;
    network: number;
  };
  bottleneckAnalysis: {
    identified: string[];
    impact: { [key: string]: number };
    recommendations: string[];
  };
}

interface OptimizationAction {
  id: string;
  type: 'parameter_adjustment' | 'resource_scaling' | 'load_balancing' | 'cache_optimization' | 'ml_training';
  component: string;
  parameters: any;
  expectedImprovement: number;
  risk: 'low' | 'medium' | 'high';
  executionTime: number;
  rollbackData: any;
}

interface MLPrediction {
  component: string;
  metric: string;
  currentValue: number;
  predictedValue: number;
  confidence: number;
  timeHorizon: number;
  factors: string[];
}

interface PerformanceBaseline {
  responseTime: { target: number; current: number; trend: 'improving' | 'degrading' | 'stable' };
  throughput: { target: number; current: number; trend: 'improving' | 'degrading' | 'stable' };
  errorRate: { target: number; current: number; trend: 'improving' | 'degrading' | 'stable' };
  resourceUtilization: { target: number; current: number; trend: 'improving' | 'degrading' | 'stable' };
}

export class AutoOptimizerV4 {
  private config = getFrameworkConfig();
  private optimizerConfig = optimizationConfig;
  private metrics: OptimizationMetrics[] = [];
  private predictions: MLPrediction[] = [];
  private performanceBaseline: PerformanceBaseline = {
    responseTime: { target: 100, current: 200, trend: 'degrading' },
    throughput: { target: 1000, current: 500, trend: 'stable' },
    errorRate: { target: 0.01, current: 0.05, trend: 'degrading' },
    resourceUtilization: { target: 70, current: 65, trend: 'stable' },
  };
  private optimizationHistory: OptimizationAction[] = [];
  private trainingData: any[] = [];
  private coordinator = getCoordinator();
  private workflowEngine = getWorkflowEngine();
  private audioVisualSystem = getAudioVisualSystem();

  private optimizationInterval?: NodeJS.Timeout;
  private metricsCollectionInterval?: NodeJS.Timeout;
  private trainingInterval?: NodeJS.Timeout;

  constructor() {
    this.initializeOptimizer();
  }

  /**
   * Inicializa el optimizador autom√°tico
   */
  private async initializeOptimizer(): Promise<void> {
    console.log('‚ö° Auto Optimizer V4.0 initializing...');
    
    // Cargar datos hist√≥ricos si existen
    await this.loadHistoricalData();
    
    // Inicializar baseline de rendimiento
    await this.initializePerformanceBaseline();
    
    // Configurar intervalos de optimizaci√≥n
    this.startOptimizationCycles();
    
    console.log('‚úÖ Auto Optimizer V4.0 initialized');
  }

  /**
   * Carga datos hist√≥ricos de rendimiento
   */
  private async loadHistoricalData(): Promise<void> {
    // En una implementaci√≥n real, esto cargar√≠a datos desde una base de datos
    // Por ahora, simulamos datos hist√≥ricos
    const now = Date.now();
    for (let i = 0; i < 24; i++) {
      this.metrics.push(this.generateSampleMetrics(new Date(now - i * 3600000)));
    }
    console.log(`üìä Loaded ${this.metrics.length} historical metrics`);
  }

  /**
   * Inicializa el baseline de rendimiento
   */
  private async initializePerformanceBaseline(): Promise<void> {
    if (this.metrics.length > 0) {
      const latest = this.metrics[this.metrics.length - 1];
      this.performanceBaseline = {
        responseTime: {
          target: this.optimizerConfig.performance.targetResponseTime,
          current: latest.performance.responseTime,
          trend: this.calculateTrend('responseTime'),
        },
        throughput: {
          target: this.optimizerConfig.performance.targetThroughput,
          current: latest.performance.throughput,
          trend: this.calculateTrend('throughput'),
        },
        errorRate: {
          target: 0.01,
          current: 1 - (latest.quality.overall / 100),
          trend: this.calculateTrend('errorRate'),
        },
        resourceUtilization: {
          target: this.optimizerConfig.performance.targetCPUUsage,
          current: latest.resourceUtilization.cpu,
          trend: this.calculateTrend('resourceUtilization'),
        },
      };
    }
  }

  /**
   * Inicia los ciclos de optimizaci√≥n autom√°ticos
   */
  private startOptimizationCycles(): void {
    // Recolecci√≥n de m√©tricas cada 30 segundos
    this.metricsCollectionInterval = setInterval(() => {
      this.collectCurrentMetrics();
    }, 30000);

    // Optimizaci√≥n cada 5 minutos
    this.optimizationInterval = setInterval(() => {
      this.performOptimization();
    }, 300000);

    // Entrenamiento de ML cada hora
    this.trainingInterval = setInterval(() => {
      this.trainMLModel();
    }, 3600000);
  }

  /**
   * Recolecta m√©tricas actuales del sistema
   */
  private async collectCurrentMetrics(): Promise<void> {
    try {
      const currentMetrics = await this.gatherSystemMetrics();
      this.metrics.push(currentMetrics);
      
      // Mantener solo los √∫ltimos 1000 registros
      if (this.metrics.length > 1000) {
        this.metrics = this.metrics.slice(-1000);
      }
      
      // Agregar a datos de entrenamiento
      this.trainingData.push(currentMetrics);
      
    } catch (error) {
      console.error('‚ùå Failed to collect metrics:', error);
    }
  }

  /**
   * Recolecta m√©tricas del sistema en tiempo real
   */
  private async gatherSystemMetrics(): Promise<OptimizationMetrics> {
    const timestamp = new Date();
    
    // Obtener m√©tricas del coordinador
    const coordinatorMetrics = this.coordinator.getMetrics();
    
    // Obtener m√©tricas del workflow engine
    const workflowMetrics = this.workflowEngine.getMetrics();
    
    // Obtener m√©tricas del sistema audiovisual
    // (en implementaci√≥n real, esto obtendr√≠a m√©tricas reales)
    
    return {
      timestamp,
      performance: {
        responseTime: this.calculateAverageResponseTime(coordinatorMetrics),
        throughput: coordinatorMetrics.throughput,
        cpuUsage: this.getCurrentCPUUsage(),
        memoryUsage: this.getCurrentMemoryUsage(),
        diskUsage: this.getCurrentDiskUsage(),
        networkLatency: this.getCurrentNetworkLatency(),
      },
      quality: {
        overall: this.calculateOverallQuality(workflowMetrics),
        byComponent: {
          coordinator: 95,
          workflow: 92,
          audiovisual: 96,
          qa: 98,
        },
        trends: this.calculateQualityTrends(),
      },
      resourceUtilization: {
        cpu: this.getCurrentCPUUsage(),
        memory: this.getCurrentMemoryUsage(),
        storage: this.getCurrentDiskUsage(),
        network: this.getCurrentNetworkLatency() / 100, // Normalizar
      },
      bottleneckAnalysis: this.identifyBottlenecks(coordinatorMetrics, workflowMetrics),
    };
  }

  /**
   * Realiza optimizaci√≥n autom√°tica
   */
  private async performOptimization(): Promise<void> {
    console.log('üîß Starting automatic optimization cycle...');
    
    try {
      // 1. Analizar rendimiento actual
      const performanceAnalysis = await this.analyzePerformance();
      
      // 2. Identificar oportunidades de mejora
      const optimizationOpportunities = await this.identifyOptimizationOpportunities(performanceAnalysis);
      
      // 3. Generar predicciones ML
      const predictions = await this.generateMLPredictions();
      
      // 4. Crear plan de optimizaci√≥n
      const optimizationPlan = await this.createOptimizationPlan(optimizationOpportunities, predictions);
      
      // 5. Ejecutar optimizaciones (si est√°n habilitadas)
      if (this.config.optimization.enabled) {
        await this.executeOptimizationPlan(optimizationPlan);
      }
      
      console.log(`‚úÖ Optimization cycle completed: ${optimizationPlan.length} actions planned`);
    } catch (error) {
      console.error('‚ùå Optimization cycle failed:', error);
    }
  }

  /**
   * Analiza el rendimiento actual
   */
  private async analyzePerformance(): Promise<any> {
    if (this.metrics.length < 2) {
      return { analysis: 'insufficient_data' };
    }
    
    const latest = this.metrics[this.metrics.length - 1];
    const previous = this.metrics[this.metrics.length - 2];
    
    return {
      responseTimeChange: latest.performance.responseTime - previous.performance.responseTime,
      throughputChange: latest.performance.throughput - previous.performance.throughput,
      qualityChange: latest.quality.overall - previous.quality.overall,
      resourceTrend: this.calculateResourceTrend(),
      recommendations: this.generatePerformanceRecommendations(latest, previous),
    };
  }

  /**
   * Identifica oportunidades de optimizaci√≥n
   */
  private async identifyOptimizationOpportunities(analysis: any): Promise<OptimizationAction[]> {
    const opportunities: OptimizationAction[] = [];
    
    // Oportunidades de respuesta
    if (analysis.responseTimeChange > 50) {
      opportunities.push({
        id: `opt_response_time_${Date.now()}`,
        type: 'parameter_adjustment',
        component: 'coordinator',
        parameters: { maxConcurrentTasks: this.coordinator.getMetrics().activeTasks * 1.2 },
        expectedImprovement: -30,
        risk: 'low',
        executionTime: 1000,
        rollbackData: { maxConcurrentTasks: this.coordinator.getMetrics().activeTasks },
      });
    }
    
    // Oportunidades de throughput
    if (analysis.throughputChange < 0) {
      opportunities.push({
        id: `opt_throughput_${Date.now()}`,
        type: 'load_balancing',
        component: 'coordinator',
        parameters: { autoLoadBalancing: true },
        expectedImprovement: 25,
        risk: 'low',
        executionTime: 2000,
        rollbackData: { autoLoadBalancing: false },
      });
    }
    
    // Oportunidades de recursos
    if (analysis.resourceTrend === 'increasing') {
      opportunities.push({
        id: `opt_resources_${Date.now()}`,
        type: 'resource_scaling',
        component: 'system',
        parameters: { scaleUp: true },
        expectedImprovement: 20,
        risk: 'medium',
        executionTime: 10000,
        rollbackData: { scaleUp: false },
      });
    }
    
    // Oportunidades de calidad
    if (analysis.qualityChange < -5) {
      opportunities.push({
        id: `opt_quality_${Date.now()}`,
        type: 'parameter_adjustment',
        component: 'qa',
        parameters: { qualityThreshold: 90 },
        expectedImprovement: 15,
        risk: 'low',
        executionTime: 500,
        rollbackData: { qualityThreshold: 85 },
      });
    }
    
    return opportunities;
  }

  /**
   * Genera predicciones de ML
   */
  private async generateMLPredictions(): Promise<MLPrediction[]> {
    if (this.trainingData.length < 10) {
      return []; // Necesita m√°s datos para hacer predicciones
    }
    
    const predictions: MLPrediction[] = [];
    
    // Predicci√≥n de response time
    predictions.push({
      component: 'coordinator',
      metric: 'responseTime',
      currentValue: this.getCurrentResponseTime(),
      predictedValue: this.predictNextResponseTime(),
      confidence: 0.85,
      timeHorizon: 30, // 30 minutos
      factors: ['queueLength', 'teamsUtilization', 'cpuUsage'],
    });
    
    // Predicci√≥n de throughput
    predictions.push({
      component: 'workflowEngine',
      metric: 'throughput',
      currentValue: this.getCurrentThroughput(),
      predictedValue: this.predictNextThroughput(),
      confidence: 0.78,
      timeHorizon: 60, // 1 hora
      factors: ['activeWorkflows', 'stepComplexity', 'resourceUtilization'],
    });
    
    // Predicci√≥n de calidad
    predictions.push({
      component: 'system',
      metric: 'overallQuality',
      currentValue: this.getCurrentQuality(),
      predictedValue: this.predictNextQuality(),
      confidence: 0.92,
      timeHorizon: 45, // 45 minutos
      factors: ['qaScore', 'errorRate', 'optimizationLevel'],
    });
    
    return predictions;
  }

  /**
   * Crea plan de optimizaci√≥n
   */
  private async createOptimizationPlan(opportunities: OptimizationAction[], predictions: MLPrediction[]): Promise<OptimizationAction[]> {
    const plan: OptimizationAction[] = [];
    
    // Agregar oportunidades de optimizaci√≥n
    plan.push(...opportunities);
    
    // Agregar optimizaciones predictivas basadas en ML
    for (const prediction of predictions) {
      if (prediction.confidence > 0.7 && this.shouldOptimizeBasedOnPrediction(prediction)) {
        const action = this.createPredictiveOptimizationAction(prediction);
        if (action) {
          plan.push(action);
        }
      }
    }
    
    // Ordenar por prioridad (mayor expectedImprovement primero)
    return plan.sort((a, b) => b.expectedImprovement - a.expectedImprovement);
  }

  /**
   * Ejecuta el plan de optimizaci√≥n
   */
  private async executeOptimizationPlan(plan: OptimizationAction[]): Promise<void> {
    const executedActions: OptimizationAction[] = [];
    
    for (const action of plan) {
      try {
        console.log(`üîß Executing optimization: ${action.type} on ${action.component}`);
        
        // Ejecutar acci√≥n de optimizaci√≥n
        await this.executeOptimizationAction(action);
        
        // Registrar acci√≥n ejecutada
        executedActions.push(action);
        
        // Esperar un poco antes de la siguiente acci√≥n
        await new Promise(resolve => setTimeout(resolve, 1000));
        
      } catch (error) {
        console.error(`‚ùå Optimization action failed: ${action.id}`, error);
        
        // Intentar rollback
        await this.rollbackOptimizationAction(action);
      }
    }
    
    // Agregar al historial
    this.optimizationHistory.push(...executedActions);
    
    console.log(`‚úÖ Executed ${executedActions.length} optimization actions`);
  }

  /**
   * Ejecuta una acci√≥n de optimizaci√≥n espec√≠fica
   */
  private async executeOptimizationAction(action: OptimizationAction): Promise<void> {
    switch (action.type) {
      case 'parameter_adjustment':
        await this.executeParameterAdjustment(action);
        break;
      case 'load_balancing':
        await this.executeLoadBalancing(action);
        break;
      case 'resource_scaling':
        await this.executeResourceScaling(action);
        break;
      case 'cache_optimization':
        await this.executeCacheOptimization(action);
        break;
      case 'ml_training':
        await this.executeMLTraining(action);
        break;
      default:
        throw new Error(`Unknown optimization action type: ${action.type}`);
    }
  }

  /**
   * Ejecuta ajuste de par√°metros
   */
  private async executeParameterAdjustment(action: OptimizationAction): Promise<void> {
    const { component, parameters } = action;
    
    switch (component) {
      case 'coordinator':
        // Ajustar par√°metros del coordinador
        if (parameters.maxConcurrentTasks) {
          console.log(`üîß Adjusting coordinator maxConcurrentTasks to ${parameters.maxConcurrentTasks}`);
          // En implementaci√≥n real, esto ajustar√≠a el par√°metro real
        }
        break;
        
      case 'qa':
        // Ajustar par√°metros de QA
        if (parameters.qualityThreshold) {
          console.log(`üîß Adjusting QA quality threshold to ${parameters.qualityThreshold}`);
        }
        break;
        
      default:
        throw new Error(`Unknown component for parameter adjustment: ${component}`);
    }
  }

  /**
   * Ejecuta balanceo de carga
   */
  private async executeLoadBalancing(action: OptimizationAction): Promise<void> {
    if (action.parameters.autoLoadBalancing) {
      console.log('üîß Enabling automatic load balancing');
      // En implementaci√≥n real, activar√≠a el balanceo de carga autom√°tico
    }
  }

  /**
   * Ejecuta escalado de recursos
   */
  private async executeResourceScaling(action: OptimizationAction): Promise<void> {
    if (action.parameters.scaleUp) {
      console.log('üîß Scaling up system resources');
      // En implementaci√≥n real, escalar√≠a recursos (CPU, memoria, etc.)
    }
  }

  /**
   * Ejecuta optimizaci√≥n de cache
   */
  private async executeCacheOptimization(action: OptimizationAction): Promise<void> {
    console.log('üîß Optimizing cache performance');
    // En implementaci√≥n real, optimizar√≠a estrategias de cache
  }

  /**
   * Entrena modelo de ML
   */
  private async executeMLTraining(action: OptimizationAction): Promise<void> {
    console.log('üîß Training ML model');
    await this.trainMLModel();
  }

  /**
   * Entrena el modelo de ML
   */
  private async trainMLModel(): Promise<void> {
    if (this.trainingData.length < 100) {
      console.log('‚è≥ Insufficient data for ML training, waiting for more data...');
      return;
    }
    
    try {
      console.log('üß† Training ML model with', this.trainingData.length, 'data points...');
      
      // Simular entrenamiento de modelo
      await new Promise(resolve => setTimeout(resolve, 5000));
      
      // En una implementaci√≥n real, aqu√≠ se entrenar√≠a un modelo real
      // usando TensorFlow, scikit-learn, o similar
      
      console.log('‚úÖ ML model training completed');
    } catch (error) {
      console.error('‚ùå ML training failed:', error);
    }
  }

  /**
   * Realiza rollback de una acci√≥n de optimizaci√≥n
   */
  private async rollbackOptimizationAction(action: OptimizationAction): Promise<void> {
    console.log(`üîÑ Rolling back optimization: ${action.id}`);
    
    try {
      // Aplicar datos de rollback
      if (action.rollbackData) {
        await this.applyRollbackData(action.component, action.rollbackData);
      }
      
      console.log(`‚úÖ Rollback completed for: ${action.id}`);
    } catch (error) {
      console.error(`‚ùå Rollback failed for: ${action.id}`, error);
    }
  }

  /**
   * Aplica datos de rollback
   */
  private async applyRollbackData(component: string, rollbackData: any): Promise<void> {
    switch (component) {
      case 'coordinator':
        if (rollbackData.maxConcurrentTasks) {
          console.log(`üîÑ Rolling back maxConcurrentTasks to ${rollbackData.maxConcurrentTasks}`);
        }
        break;
      case 'qa':
        if (rollbackData.qualityThreshold) {
          console.log(`üîÑ Rolling back quality threshold to ${rollbackData.qualityThreshold}`);
        }
        break;
    }
  }

  // ================================
  // M√âTODOS DE PREDICCI√ìN Y AN√ÅLISIS
  // ================================

  private getCurrentResponseTime(): number {
    const latest = this.metrics[this.metrics.length - 1];
    return latest?.performance.responseTime || 200;
  }

  private predictNextResponseTime(): number {
    // Algoritmo simple de predicci√≥n basado en tendencia
    const recent = this.metrics.slice(-5);
    if (recent.length < 2) return this.getCurrentResponseTime();
    
    const trend = (recent[recent.length - 1].performance.responseTime - recent[0].performance.responseTime) / recent.length;
    return this.getCurrentResponseTime() + trend;
  }

  private getCurrentThroughput(): number {
    const latest = this.metrics[this.metrics.length - 1];
    return latest?.performance.throughput || 500;
  }

  private predictNextThroughput(): number {
    const recent = this.metrics.slice(-5);
    if (recent.length < 2) return this.getCurrentThroughput();
    
    const trend = (recent[recent.length - 1].performance.throughput - recent[0].performance.throughput) / recent.length;
    return this.getCurrentThroughput() + trend;
  }

  private getCurrentQuality(): number {
    const latest = this.metrics[this.metrics.length - 1];
    return latest?.quality.overall || 90;
  }

  private predictNextQuality(): number {
    const recent = this.metrics.slice(-5);
    if (recent.length < 2) return this.getCurrentQuality();
    
    const trend = (recent[recent.length - 1].quality.overall - recent[0].quality.overall) / recent.length;
    return this.getCurrentQuality() + trend;
  }

  private shouldOptimizeBasedOnPrediction(prediction: MLPrediction): boolean {
    // Decidir si se debe optimizar basado en la predicci√≥n
    const degradation = prediction.predictedValue - prediction.currentValue;
    const threshold = prediction.metric === 'responseTime' ? 50 : 10;
    
    return degradation > threshold && prediction.confidence > 0.7;
  }

  private createPredictiveOptimizationAction(prediction: MLPrediction): OptimizationAction | null {
    if (prediction.metric === 'responseTime' && prediction.predictedValue > prediction.currentValue + 50) {
      return {
        id: `pred_opt_${Date.now()}`,
        type: 'parameter_adjustment',
        component: prediction.component,
        parameters: { optimizationLevel: 'aggressive' },
        expectedImprovement: -25,
        risk: 'low',
        executionTime: 2000,
        rollbackData: { optimizationLevel: 'normal' },
      };
    }
    
    return null;
  }

  // ================================
  // M√âTODOS DE UTILIDAD
  // ================================

  private calculateAverageResponseTime(metrics: any): number {
    return metrics.averageResponseTime || 200;
  }

  private getCurrentCPUUsage(): number {
    // Simular uso de CPU
    return Math.random() * 80 + 10; // 10-90%
  }

  private getCurrentMemoryUsage(): number {
    // Simular uso de memoria
    return Math.random() * 70 + 20; // 20-90%
  }

  private getCurrentDiskUsage(): number {
    // Simular uso de disco
    return Math.random() * 50 + 30; // 30-80%
  }

  private getCurrentNetworkLatency(): number {
    // Simular latencia de red
    return Math.random() * 20 + 5; // 5-25ms
  }

  private calculateOverallQuality(metrics: any): number {
    return metrics.successRate ? metrics.successRate * 100 : 95;
  }

  private calculateQualityTrends(): { [key: string]: number[] } {
    const trends: { [key: string]: number[] } = {};
    const recent = this.metrics.slice(-10);
    
    for (const metric of Object.keys(recent[0]?.quality.byComponent || {})) {
      trends[metric] = recent.map(m => m.quality.byComponent[metric] || 90);
    }
    
    return trends;
  }

  private identifyBottlenecks(coordinatorMetrics: any, workflowMetrics: any): any {
    const bottlenecks: string[] = [];
    const impact: { [key: string]: number } = {};
    const recommendations: string[] = [];
    
    // Identificar cuellos de botella en el coordinador
    if (coordinatorMetrics.queueLength > 20) {
      bottlenecks.push('high_queue_length');
      impact['high_queue_length'] = 0.8;
      recommendations.push('Increase coordinator capacity or optimize task assignment');
    }
    
    // Identificar cuellos de botella en workflows
    if (workflowMetrics.activeWorkflows > 10) {
      bottlenecks.push('high_workload');
      impact['high_workload'] = 0.6;
      recommendations.push('Scale up workflow processing capacity');
    }
    
    // Identificar problemas de recursos
    const cpuUsage = this.getCurrentCPUUsage();
    if (cpuUsage > 80) {
      bottlenecks.push('high_cpu_usage');
      impact['high_cpu_usage'] = 0.9;
      recommendations.push('Scale up CPU resources or optimize CPU-intensive operations');
    }
    
    return { identified: bottlenecks, impact, recommendations };
  }

  private calculateTrend(metric: string): 'improving' | 'degrading' | 'stable' {
    if (this.metrics.length < 3) return 'stable';
    
    const recent = this.metrics.slice(-3);
    const values = recent.map(m => {
      switch (metric) {
        case 'responseTime':
          return m.performance.responseTime;
        case 'throughput':
          return m.performance.throughput;
        case 'errorRate':
          return 1 - (m.quality.overall / 100);
        case 'resourceUtilization':
          return m.resourceUtilization.cpu;
        default:
          return 0;
      }
    });
    
    const change1 = values[1] - values[0];
    const change2 = values[2] - values[1];
    
    if (change1 > 0 && change2 > 0) {
      return metric === 'responseTime' ? 'degrading' : 'improving';
    } else if (change1 < 0 && change2 < 0) {
      return metric === 'responseTime' ? 'improving' : 'degrading';
    } else {
      return 'stable';
    }
  }

  private calculateResourceTrend(): 'increasing' | 'decreasing' | 'stable' {
    if (this.metrics.length < 3) return 'stable';
    
    const recent = this.metrics.slice(-3);
    const cpuValues = recent.map(m => m.resourceUtilization.cpu);
    
    const change = (cpuValues[2] - cpuValues[0]) / 2;
    
    if (change > 5) return 'increasing';
    if (change < -5) return 'decreasing';
    return 'stable';
  }

  private generatePerformanceRecommendations(latest: any, previous: any): string[] {
    const recommendations: string[] = [];
    
    if (latest.performance.responseTime > previous.performance.responseTime * 1.2) {
      recommendations.push('Response time is degrading, consider optimizing task assignment');
    }
    
    if (latest.resourceUtilization.cpu > 80) {
      recommendations.push('High CPU usage detected, consider scaling up resources');
    }
    
    if (latest.quality.overall < previous.quality.overall * 0.95) {
      recommendations.push('Quality metrics are declining, review QA processes');
    }
    
    return recommendations;
  }

  private generateSampleMetrics(timestamp: Date): OptimizationMetrics {
    return {
      timestamp,
      performance: {
        responseTime: 150 + Math.random() * 100,
        throughput: 400 + Math.random() * 200,
        cpuUsage: 30 + Math.random() * 40,
        memoryUsage: 40 + Math.random() * 30,
        diskUsage: 20 + Math.random() * 30,
        networkLatency: 5 + Math.random() * 15,
      },
      quality: {
        overall: 90 + Math.random() * 10,
        byComponent: {
          coordinator: 92 + Math.random() * 8,
          workflow: 88 + Math.random() * 12,
          audiovisual: 94 + Math.random() * 6,
          qa: 96 + Math.random() * 4,
        },
        trends: {
          coordinator: [92, 93, 91, 94, 95],
          workflow: [88, 87, 89, 90, 88],
        },
      },
      resourceUtilization: {
        cpu: 35 + Math.random() * 30,
        memory: 45 + Math.random() * 25,
        storage: 25 + Math.random() * 20,
        network: 15 + Math.random() * 20,
      },
      bottleneckAnalysis: {
        identified: [],
        impact: {},
        recommendations: [],
      },
    };
  }

  // ================================
  // M√âTODOS P√öBLICOS
  // ================================

  getOptimizationMetrics(): OptimizationMetrics[] {
    return [...this.metrics];
  }

  getPerformanceBaseline(): PerformanceBaseline {
    return { ...this.performanceBaseline };
  }

  getOptimizationHistory(): OptimizationAction[] {
    return [...this.optimizationHistory];
  }

  async manualOptimization(component?: string): Promise<OptimizationAction[]> {
    console.log('üîß Starting manual optimization...');
    await this.performOptimization();
    return this.optimizationHistory.slice(-10);
  }

  stopOptimizer(): void {
    if (this.optimizationInterval) clearInterval(this.optimizationInterval);
    if (this.metricsCollectionInterval) clearInterval(this.metricsCollectionInterval);
    if (this.trainingInterval) clearInterval(this.trainingInterval);
    console.log('üõë Auto Optimizer stopped');
  }
}

// Singleton global
let globalAutoOptimizer: AutoOptimizerV4 | null = null;

export function getAutoOptimizer(): AutoOptimizerV4 {
  if (!globalAutoOptimizer) {
    globalAutoOptimizer = new AutoOptimizerV4();
  }
  return globalAutoOptimizer;
}

export { AutoOptimizerV4 };
