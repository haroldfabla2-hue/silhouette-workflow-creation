# CI/CD Pipeline - Completo

## Descripci√≥n General

El **CI/CD Pipeline** de Silhouette Workflow Creation es un sistema de integraci√≥n y despliegue continuo completamente automatizado que garantiza entregas r√°pidas, confiables y seguras. Este pipeline implementa GitHub Actions con Docker, automatiza el testing completo, y maneja despliegues a m√∫ltiples entornos con rollback autom√°tico y monitoreo integrado.

## Arquitectura del Pipeline CI/CD

### Componentes del Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   CI/CD PIPELINE ARCHITECTURE               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ SOURCE CONTROL  ‚îÇ  ‚îÇ BUILD STAGE     ‚îÇ  ‚îÇ TEST STAGE   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Git Push      ‚îÇ  ‚îÇ ‚Ä¢ Docker Build  ‚îÇ  ‚îÇ ‚Ä¢ Unit Tests ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ PR Creation   ‚îÇ  ‚îÇ ‚Ä¢ Dependency    ‚îÇ  ‚îÇ ‚Ä¢ Integration‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Merge Review  ‚îÇ  ‚îÇ ‚Ä¢ Security Scan ‚îÇ  ‚îÇ ‚Ä¢ E2E Tests  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Branch Rules  ‚îÇ  ‚îÇ ‚Ä¢ Multi-arch    ‚îÇ  ‚îÇ ‚Ä¢ API Tests  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ DEPLOY STAGE    ‚îÇ  ‚îÇ MONITORING      ‚îÇ  ‚îÇ ROLLBACK     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Docker Push   ‚îÇ  ‚îÇ ‚Ä¢ Health Checks ‚îÇ  ‚îÇ ‚Ä¢ Auto       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ K8s Deploy    ‚îÇ  ‚îÇ ‚Ä¢ Metrics       ‚îÇ  ‚îÇ ‚Ä¢ Manual     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Staging       ‚îÇ  ‚îÇ ‚Ä¢ Alerts        ‚îÇ  ‚îÇ ‚Ä¢ Blue/Green ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Production    ‚îÇ  ‚îÇ ‚Ä¢ Logs          ‚îÇ  ‚îÇ ‚Ä¢ Canary     ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ QUALITY GATES   ‚îÇ  ‚îÇ SECURITY SCAN   ‚îÇ  ‚îÇ NOTIFICATIONS‚îÇ ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Code Review   ‚îÇ  ‚îÇ ‚Ä¢ SAST          ‚îÇ  ‚îÇ ‚Ä¢ Slack      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Coverage      ‚îÇ  ‚îÇ ‚Ä¢ DAST          ‚îÇ  ‚îÇ ‚Ä¢ Email      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Performance   ‚îÇ  ‚îÇ ‚Ä¢ Dependencies  ‚îÇ  ‚îÇ ‚Ä¢ Teams      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Compliance    ‚îÇ  ‚îÇ ‚Ä¢ Container     ‚îÇ  ‚îÇ ‚Ä¢ Webhooks   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## 1. GitHub Actions Workflow

### Workflow Principal de CI/CD

```yaml
# .github/workflows/ci-cd.yml
name: Silhouette Workflow CI/CD Pipeline

on:
  push:
    branches: [ main, develop, staging ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # Job 1: Code Quality and Security Analysis
  code-quality:
    name: Code Quality & Security Analysis
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for SonarQube

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: '**/package-lock.json'

      - name: Install dependencies
        run: |
          npm ci
          npm run build:deps

      - name: Run ESLint
        run: npm run lint
        continue-on-error: false

      - name: Run Prettier check
        run: npm run format:check
        continue-on-error: false

      - name: SonarQube Scan
        uses: sonarqube-quality-gate-action@master
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}

      - name: CodeQL Security Analysis
        uses: github/codeql-action/analyze@v2
        with:
          languages: javascript,typescript
          queries: security-extended

  # Job 2: Backend Testing
  backend-test:
    name: Backend Testing
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_USER: test
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

      rabbitmq:
        image: rabbitmq:3-management
        env:
          RABBITMQ_DEFAULT_USER: test
          RABBITMQ_DEFAULT_PASS: test
        options: >-
          --health-cmd "rabbitmq-diagnostics check_port_connectivity"
          --health-interval 30s
          --health-timeout 30s
          --health-retries 3
        ports:
          - 5672:5672
          - 15672:15672

      neo4j:
        image: neo4j:5
        env:
          NEO4J_AUTH: neo4j/test
        options: >-
          --health-cmd "cypher-shell -u neo4j -p test 'RETURN 1'"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 7687:7687
          - 7474:7474

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: 'backend/package-lock.json'

      - name: Install backend dependencies
        working-directory: backend
        run: npm ci

      - name: Run unit tests
        working-directory: backend
        env:
          NODE_ENV: test
          DATABASE_URL: postgresql://test:test@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379
          RABBITMQ_URL: amqp://test:test@localhost:5672
          NEO4J_URI: bolt://localhost:7687
        run: |
          npm run test:unit
          npm run test:coverage

      - name: Run integration tests
        working-directory: backend
        env:
          NODE_ENV: test
          DATABASE_URL: postgresql://test:test@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379
          RABBITMQ_URL: amqp://test:test@localhost:5672
          NEO4J_URI: bolt://localhost:7687
        run: npm run test:integration

      - name: Run API tests
        working-directory: api-tests
        run: |
          npm ci
          npm run test:contract

      - name: Upload test results
        uses: actions/upload-artifact@v3
        with:
          name: backend-test-results
          path: |
            backend/coverage/
            backend/test-results/
            api-tests/reports/

  # Job 3: Frontend Testing
  frontend-test:
    name: Frontend Testing
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: 'frontend/package-lock.json'

      - name: Install frontend dependencies
        working-directory: frontend
        run: npm ci

      - name: Run unit tests
        working-directory: frontend
        run: |
          npm run test:unit
          npm run test:coverage

      - name: Run E2E tests
        working-directory: frontend
        env:
          CYPRESS_baseUrl: http://localhost:3000
        run: |
          npm run build
          npm run start:test &
          sleep 30
          npm run test:e2e
          npm run cypress:run

      - name: Upload test results
        uses: actions/upload-artifact@v3
        with:
          name: frontend-test-results
          path: |
            frontend/coverage/
            frontend/cypress/videos/
            frontend/cypress/screenshots/

  # Job 4: Mobile Testing
  mobile-test:
    name: Mobile Testing
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install mobile dependencies
        working-directory: mobile
        run: npm ci

      - name: Run mobile tests
        working-directory: mobile
        env:
          NODE_ENV: test
        run: |
          npm run test:unit
          npm run test:integration
          npm run test:coverage

      - name: Upload test results
        uses: actions/upload-artifact@v3
        with:
          name: mobile-test-results
          path: mobile/coverage/

  # Job 5: Performance Testing
  performance-test:
    name: Performance Testing
    runs-on: ubuntu-latest
    needs: [backend-test, frontend-test]
    if: github.ref == 'refs/heads/main' || github.event_name == 'schedule'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup K6
        run: |
          sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Build application
        run: |
          npm run build
          docker-compose up -d

      - name: Wait for services
        run: |
          timeout 60 bash -c 'until curl -f http://localhost:3000; do sleep 5; done'
          timeout 60 bash -c 'until curl -f http://localhost:8000/health; do sleep 5; done'

      - name: Run K6 performance tests
        run: |
          k6 run performance-tests/workflow-api-load.js
          k6 run performance-tests/frontend-load.js

      - name: Upload performance results
        uses: actions/upload-artifact@v3
        with:
          name: performance-test-results
          path: performance-tests/results/

  # Job 6: Security Testing
  security-test:
    name: Security Testing
    runs-on: ubuntu-latest
    needs: [code-quality]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Snyk security scan
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high

      - name: Run OWASP ZAP scan
        uses: zaproxy/action-full-scan@v0.4.0
        with:
          target: 'https://staging.silhouette-workflow.com'
          rules_file_name: '.zap/rules.tsv'
          cmd_options: '-a'

  # Job 7: Build and Push Docker Images
  build-and-push:
    name: Build and Push Docker Images
    runs-on: ubuntu-latest
    needs: [code-quality, backend-test, frontend-test, mobile-test, security-test]
    if: github.event_name == 'push' || github.event_name == 'schedule'
    outputs:
      backend-image: ${{ steps.meta-backend.outputs.digest }}
      frontend-image: ${{ steps.meta-frontend.outputs.digest }}
      mobile-image: ${{ steps.meta-mobile.outputs.digest }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Log in to Container Registry
        uses: docker/login-action@v2
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta-backend
        uses: docker/metadata-action@v4
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-backend
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Extract metadata (frontend)
        id: meta-frontend
        uses: docker/metadata-action@v4
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-frontend
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Extract metadata (mobile)
        id: meta-mobile
        uses: docker/metadata-action@v4
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-mobile
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push backend image
        uses: docker/build-push-action@v4
        with:
          context: ./backend
          file: ./backend/Dockerfile
          push: true
          tags: ${{ steps.meta-backend.outputs.tags }}
          labels: ${{ steps.meta-backend.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build and push frontend image
        uses: docker/build-push-action@v4
        with:
          context: ./frontend
          file: ./frontend/Dockerfile
          push: true
          tags: ${{ steps.meta-frontend.outputs.tags }}
          labels: ${{ steps.meta-frontend.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build and push mobile image
        uses: docker/build-push-action@v4
        with:
          context: ./mobile
          file: ./mobile/Dockerfile
          push: true
          tags: ${{ steps.meta-mobile.outputs.tags }}
          labels: ${{ steps.meta-mobile.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # Job 8: Deploy to Staging
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [build-and-push, performance-test]
    if: github.ref == 'refs/heads/develop' || github.ref == 'refs/heads/staging'
    environment:
      name: staging
      url: https://staging.silhouette-workflow.com
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'

      - name: Configure kubectl
        run: |
          echo "${{ secrets.KUBE_CONFIG_STAGING }}" | base64 -d > kubeconfig
          export KUBECONFIG=kubeconfig

      - name: Deploy to staging
        run: |
          export KUBECONFIG=kubeconfig
          helm upgrade --install silhouette-workflow-staging \
            config/helm/silhouette-workflow/ \
            --namespace staging \
            --create-namespace \
            --set image.tag=${{ github.sha }} \
            --set image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-backend \
            --set frontend.image.tag=${{ github.sha }} \
            --set frontend.image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-frontend \
            --set replicaCount=2 \
            --set environment=staging

      - name: Wait for deployment
        run: |
          export KUBECONFIG=kubeconfig
          kubectl wait --for=condition=available --timeout=300s deployment/silhouette-workflow-staging -n staging
          kubectl wait --for=condition=available --timeout=300s deployment/silhouette-workflow-frontend-staging -n staging

      - name: Run smoke tests
        run: |
          export KUBECONFIG=kubeconfig
          kubectl run smoke-test --image=curlimages/curl --rm -i --restart=Never -- \
            curl -f https://staging.silhouette-workflow.com/health
          kubectl run api-smoke-test --image=curlimages/curl --rm -i --restart=Never -- \
            curl -f https://staging.silhouette-workflow.com/api/health

      - name: Update deployment status
        run: |
          echo "‚úÖ Staging deployment completed successfully"
          echo "üîó URL: https://staging.silhouette-workflow.com"
          echo "üìä Commit: ${{ github.sha }}"
          echo "üë§ Author: ${{ github.actor }}"

  # Job 9: Deploy to Production
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [build-and-push, deploy-staging]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment:
      name: production
      url: https://silhouette-workflow.com
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'

      - name: Configure kubectl
        run: |
          echo "${{ secrets.KUBE_CONFIG_PRODUCTION }}" | base64 -d > kubeconfig
          export KUBECONFIG=kubeconfig

      - name: Create backup before deployment
        run: |
          export KUBECONFIG=kubeconfig
          kubectl create job --from=cronjob/backup-job backup-$(date +%Y%m%d-%H%M%S) -n production

      - name: Blue/Green deployment
        run: |
          export KUBECONFIG=kubeconfig
          
          # Deploy to green environment
          helm upgrade --install silhouette-workflow-green \
            config/helm/silhouette-workflow/ \
            --namespace production \
            --create-namespace \
            --set image.tag=${{ github.sha }} \
            --set image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-backend \
            --set frontend.image.tag=${{ github.sha }} \
            --set frontend.image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}-frontend \
            --set replicaCount=5 \
            --set environment=green \
            --set service.type=ClusterIP

      - name: Wait for green deployment
        run: |
          export KUBECONFIG=kubeconfig
          kubectl wait --for=condition=available --timeout=600s deployment/silhouette-workflow-green -n production
          kubectl wait --for=condition=available --timeout=600s deployment/silhouette-workflow-frontend-green -n production

      - name: Run comprehensive health checks
        run: |
          export KUBECONFIG=kubeconfig
          # Check all pods are ready
          kubectl get pods -n production -l app=silhouette-workflow-green
          # Check services
          kubectl get services -n production -l app=silhouette-workflow-green

      - name: Switch traffic to green
        run: |
          export KUBECONFIG=kubeconfig
          # Update ingress to point to green
          kubectl patch ingress silhouette-workflow-ingress -n production -p \
            '{"spec":{"rules":[{"host":"silhouette-workflow.com","http":{"paths":[{"backend":{"service":{"name":"silhouette-workflow-frontend-green","port":{"number":80}}}}]}}]}}'

      - name: Monitor deployment
        run: |
          export KUBECONFIG=kubeconfig
          # Wait 5 minutes for traffic switch
          sleep 300
          # Check for any errors
          kubectl logs -n production -l app=silhouette-workflow-green --tail=100 | grep -i error || echo "No errors found"

      - name: Switch blue to green
        run: |
          export KUBECONFIG=kubeconfig
          # Scale down blue environment
          kubectl scale deployment/silhouette-workflow-blue --replicas=0 -n production
          kubectl scale deployment/silhouette-workflow-frontend-blue --replicas=0 -n production
          
          # Rename green to blue for next deployment
          kubectl patch deployment silhouette-workflow-green -n production -p \
            '{"metadata":{"labels":{"version":"blue"}}}'
          kubectl patch service silhouette-workflow-frontend -n production -p \
            '{"spec":{"selector":{"app":"silhouette-workflow-green","version":"blue"}}}'

      - name: Post-deployment verification
        run: |
          export KUBECONFIG=kubeconfig
          # Run post-deployment tests
          curl -f https://silhouette-workflow.com/health || exit 1
          curl -f https://silhouette-workflow.com/api/health || exit 1

      - name: Notify team
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#deployments'
          message: |
            üéâ Production deployment completed successfully!
            - Commit: ${{ github.sha }}
            - Author: ${{ github.actor }}
            - URL: https://silhouette-workflow.com
            - Environment: Production
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  # Job 10: Post-deployment monitoring
  post-deployment-monitoring:
    name: Post-deployment Monitoring
    runs-on: ubuntu-latest
    needs: [deploy-production]
    if: always() && (needs.deploy-production.result == 'success' || needs.deploy-production.result == 'failure')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup monitoring
        run: |
          # Setup Prometheus and Grafana monitoring
          # This would typically involve setting up monitoring dashboards
          # and alerts for the new deployment

      - name: Monitor for errors
        run: |
          # Monitor for errors in the first 10 minutes after deployment
          for i in {1..12}; do
            echo "Monitoring check $i/12"
            # Check error rates, response times, etc.
            sleep 60
          done

      - name: Send final status
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#deployments'
          message: |
            üìä Post-deployment monitoring completed
            - Deployment: ${{ needs.deploy-production.result }}
            - URL: https://silhouette-workflow.com
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
```

## 2. Configuraci√≥n de GitHub Actions Espec√≠fica

### Workflow de Dependabot

```yaml
# .github/workflows/dependency-updates.yml
name: Dependency Updates

on:
  schedule:
    - cron: '0 3 * * 1'  # Every Monday at 3 AM
  workflow_dispatch:

jobs:
  dependency-updates:
    name: Dependency Updates
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Update dependencies
        run: |
          # Update all package.json files
          find . -name "package.json" -not -path "./node_modules/*" -exec \
            npm update --save \;

      - name: Update package-lock files
        run: |
          find . -name "package.json" -not -path "./node_modules/*" -exec \
            npm install --package-lock-only \;

      - name: Run tests with updated dependencies
        run: |
          npm run test:all

      - name: Create Pull Request
        uses: peter-evans/create-pull-request@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: 'chore: update dependencies'
          title: 'Weekly Dependency Updates'
          body: |
            ## Dependency Updates
            
            This PR contains updated dependencies:
            
            ### Changes:
            - Updated npm dependencies to latest versions
            - Updated lock files to match package.json changes
            - Verified all tests pass with updated dependencies
            
            ### Testing:
            - All unit tests: ‚úÖ
            - Integration tests: ‚úÖ
            - E2E tests: ‚úÖ
            
            Please review and merge this PR.
          branch: dependency-updates
          delete-branch: true
```

### Workflow de Seguridad

```yaml
# .github/workflows/security.yml
name: Security Scanning

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 4 * * *'  # Daily at 4 AM

jobs:
  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run CodeQL Analysis
        uses: github/codeql-action/analyze@v2
        with:
          languages: javascript,typescript
          queries: security-extended,security-and-quality

      - name: Run Snyk to check for vulnerabilities
        uses: snyk/actions/node@master
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          args: --severity-threshold=high

      - name: Run container security scan
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: 'ghcr.io/${{ github.repository }}:${{ github.sha }}'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

      - name: Run SonarQube Security Scan
        uses: sonarqube-quality-gate-action@master
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          SONAR_HOST_URL: ${{ secrets.SONAR_HOST_URL }}
        with:
          scanMetadataReportFile: .scannerwork/report-task.txt
```

## 3. Docker Build Strategy

### Multi-stage Dockerfile para Backend

```dockerfile
# backend/Dockerfile
# Stage 1: Base image with Node.js
FROM node:18-alpine AS base
WORKDIR /app

# Install system dependencies
RUN apk add --no-cache \
    python3 \
    make \
    g++ \
    && ln -sf python3 /usr/bin/python

# Stage 2: Dependencies installation
FROM base AS dependencies
COPY package*.json ./
RUN npm ci --only=production && npm cache clean --force

# Stage 3: Development dependencies
FROM base AS dev-dependencies
COPY package*.json ./
RUN npm ci

# Stage 4: Build application
FROM base AS builder
COPY --from=dev-dependencies /app/node_modules ./node_modules
COPY . .
RUN npm run build

# Stage 5: Production image
FROM node:18-alpine AS production
WORKDIR /app

# Create non-root user
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nodejs -u 1001

# Install production dependencies
COPY --from=dependencies /app/node_modules ./node_modules
COPY --from=builder /app/dist ./dist
COPY --from=builder /app/package*.json ./

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD node dist/healthcheck.js

# Switch to non-root user
USER nodejs

# Expose port
EXPOSE 8000

# Start application
CMD ["node", "dist/server.js"]
```

### Multi-stage Dockerfile para Frontend

```dockerfile
# frontend/Dockerfile
# Stage 1: Build stage
FROM node:18-alpine AS builder
WORKDIR /app

# Install dependencies
COPY package*.json ./
RUN npm ci

# Copy source code
COPY . .

# Build application
RUN npm run build

# Stage 2: Production stage with Nginx
FROM nginx:alpine AS production

# Copy custom nginx config
COPY nginx.conf /etc/nginx/nginx.conf

# Copy built application
COPY --from=builder /app/out /usr/share/nginx/html

# Copy health check script
COPY scripts/healthcheck.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/healthcheck.sh

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD /usr/local/bin/healthcheck.sh

# Expose port
EXPOSE 80

# Start nginx
CMD ["nginx", "-g", "daemon off;"]
```

### Nginx Configuration

```nginx
# frontend/nginx.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging format
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    # Basic settings
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_min_length 1024;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/json
        application/javascript
        application/xml+rss
        application/atom+xml
        image/svg+xml;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=login:10m rate=5r/m;

    server {
        listen 80;
        server_name _;
        root /usr/share/nginx/html;
        index index.html;

        # Security headers
        add_header X-Frame-Options DENY always;
        add_header X-Content-Type-Options nosniff always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "strict-origin-when-cross-origin" always;
        add_header Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self' data:; connect-src 'self' https://api.silhouette-workflow.com wss://api.silhouette-workflow.com" always;

        # Static assets with long cache
        location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
            expires 1y;
            add_header Cache-Control "public, immutable";
        }

        # API proxy
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            proxy_pass http://backend:8000/api/;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
        }

        # Authentication endpoints with strict rate limiting
        location /api/auth/login {
            limit_req zone=login burst=5 nodelay;
            proxy_pass http://backend:8000/api/auth/login;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # SPA routing
        location / {
            try_files $uri $uri/ /index.html;
            
            # Cache control for HTML
            location ~* \.html$ {
                expires 5m;
                add_header Cache-Control "public, must-revalidate";
            }
        }

        # Health check endpoint
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }
    }
}
```

## 4. Kubernetes Deployment Configuration

### Helm Chart Structure

```yaml
# config/helm/silhouette-workflow/values.yaml
# Default values for silhouette-workflow
replicaCount: 3

image:
  repository: ghcr.io/silhouette/workflow-backend
  pullPolicy: IfNotPresent
  tag: "latest"

frontend:
  image:
    repository: ghcr.io/silhouette/workflow-frontend
    pullPolicy: IfNotPresent
    tag: "latest"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: ""

podAnnotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "8000"
  prometheus.io/path: "/metrics"

podSecurityContext:
  fsGroup: 1001
  runAsNonRoot: true
  runAsUser: 1001
  runAsGroup: 1001

securityContext:
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  capabilities:
    drop:
    - ALL

resources:
  limits:
    cpu: 500m
    memory: 1Gi
  requests:
    cpu: 100m
    memory: 256Mi

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 20
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

nodeSelector: {}
tolerations: []
affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
    - weight: 100
      podAffinityTerm:
        labelSelector:
          matchExpressions:
          - key: app.kubernetes.io/name
            operator: In
            values:
            - silhouette-workflow
        topologyKey: kubernetes.io/hostname

# Environment configuration
environment: production

# Database configuration
database:
  host: postgres
  port: 5432
  name: silhouette_workflow
  username: postgres
  existingSecret: database-credentials
  existingSecretKey: password

# Redis configuration
redis:
  host: redis
  port: 6379
  existingSecret: redis-credentials
  existingSecretKey: password

# RabbitMQ configuration
rabbitmq:
  host: rabbitmq
  port: 5672
  username: rabbitmq
  existingSecret: rabbitmq-credentials
  existingSecretKey: password

# Neo4j configuration
neo4j:
  host: neo4j
  port: 7687
  username: neo4j
  existingSecret: neo4j-credentials
  existingSecretKey: password

# Monitoring
monitoring:
  enabled: true
  serviceMonitor:
    enabled: true
    interval: 30s
    path: /metrics

# Ingress configuration
ingress:
  enabled: true
  className: nginx
  annotations:
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
  hosts:
    - host: silhouette-workflow.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: silhouette-workflow-tls
      hosts:
        - silhouette-workflow.com

# Service configuration
service:
  type: ClusterIP
  port: 80
  targetPort: 8000

frontendService:
  type: ClusterIP
  port: 80
  targetPort: 80

# Persistence
persistence:
  enabled: true
  storageClass: "fast-ssd"
  accessMode: ReadWriteOnce
  size: 20Gi
  existingClaim: ""

# Backup configuration
backup:
  enabled: true
  schedule: "0 2 * * *"
  retention: "30d"
  size: "5Gi"

# Security
security:
  networkPolicy:
    enabled: true
  podDisruptionBudget:
    minAvailable: 2
  hpa:
    enabled: true
    minReplicas: 3
    maxReplicas: 20
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80
```

### Deployment Template

```yaml
# config/helm/silhouette-workflow/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "silhouette-workflow.fullname" . }}
  labels:
    {{- include "silhouette-workflow.labels" . | nindent 4 }}
spec:
  {{- if not .Values.autoscaling.enabled }}
  replicas: {{ .Values.replicaCount }}
  {{- end }}
  selector:
    matchLabels:
      {{- include "silhouette-workflow.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      {{- with .Values.podAnnotations }}
      annotations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      labels:
        {{- include "silhouette-workflow.selectorLabels" . | nindent 8 }}
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      serviceAccountName: {{ include "silhouette-workflow.serviceAccountName" . }}
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      initContainers:
      - name: check-dependencies
        image: busybox:1.35
        command: ['sh', '-c']
        args:
        - |
          echo "Checking database connectivity..."
          if ! nc -z {{ .Values.database.host }} {{ .Values.database.port }}; then
            echo "Database is not available"
            exit 1
          fi
          echo "Database is available"
      containers:
      - name: {{ .Chart.Name }}
        securityContext:
          {{- toYaml .Values.securityContext | nindent 12 }}
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        ports:
        - name: http
          containerPort: 8000
          protocol: TCP
        - name: metrics
          containerPort: 9090
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        resources:
          {{- toYaml .Values.resources | nindent 12 }}
        env:
        - name: NODE_ENV
          value: {{ .Values.environment | quote }}
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: {{ .Values.database.existingSecret }}
              key: {{ .Values.database.existingSecretKey }}
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: {{ .Values.redis.existingSecret }}
              key: {{ .Values.redis.existingSecretKey }}
        - name: RABBITMQ_URL
          valueFrom:
            secretKeyRef:
              name: {{ .Values.rabbitmq.existingSecret }}
              key: {{ .Values.rabbitmq.existingSecretKey }}
        - name: NEO4J_URI
          valueFrom:
            secretKeyRef:
              name: {{ .Values.neo4j.existingSecret }}
              key: {{ .Values.neo4j.existingSecretKey }}
        volumeMounts:
        - name: tmp
          mountPath: /tmp
        - name: logs
          mountPath: /app/logs
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      volumes:
      - name: tmp
        emptyDir: {}
      - name: logs
        emptyDir: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "silhouette-workflow.fullname" . }}-frontend
  labels:
    {{- include "silhouette-workflow.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      {{- include "silhouette-workflow.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      labels:
        {{- include "silhouette-workflow.selectorLabels" . | nindent 8 }}
    spec:
      containers:
      - name: frontend
        image: "{{ .Values.frontend.image.repository }}:{{ .Values.frontend.image.tag }}"
        imagePullPolicy: {{ .Values.frontend.image.pullPolicy }}
        ports:
        - name: http
          containerPort: 80
          protocol: TCP
        livenessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 5
          periodSeconds: 5
        resources:
          {{- toYaml .Values.resources | nindent 12 }}
```

## 5. Monitoring y Observabilidad

### Prometheus Configuration

```yaml
# config/monitoring/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "silhouette-workflow-rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'silhouette-workflow-backend'
    static_configs:
      - targets: ['silhouette-workflow:9090']
    metrics_path: /metrics
    scrape_interval: 10s
    scrape_timeout: 5s

  - job_name: 'silhouette-workflow-frontend'
    static_configs:
      - targets: ['silhouette-workflow-frontend:80']
    metrics_path: /metrics
    scrape_interval: 30s

  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)

  - job_name: 'kubernetes-services'
    kubernetes_sd_configs:
      - role: service
    relabel_configs:
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
        action: replace
        target_label: __scheme__
        regex: (https?)
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
```

### Alert Rules

```yaml
# config/monitoring/silhouette-workflow-rules.yml
groups:
- name: silhouette-workflow.rules
  rules:
  # High-level alerts
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 2m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value }} for {{ $labels.service }}"

  - alert: HighLatency
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High latency detected"
      description: "95th percentile latency is {{ $value }}s for {{ $labels.service }}"

  - alert: HighCPUUsage
    expr: (rate(container_cpu_usage_seconds_total{pod=~"silhouette-workflow.*"}[5m]) * 100) > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High CPU usage detected"
      description: "CPU usage is {{ $value }}% for pod {{ $labels.pod }}"

  - alert: HighMemoryUsage
    expr: (container_memory_working_set_bytes{pod=~"silhouette-workflow.*"} / container_spec_memory_limit_bytes{pod=~"silhouette-workflow.*"} * 100) > 85
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage detected"
      description: "Memory usage is {{ $value }}% for pod {{ $labels.pod }}"

  - alert: PodCrashLooping
    expr: rate(kube_pod_container_status_restarts_total{pod=~"silhouette-workflow.*"}[15m]) > 0
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "Pod is crash looping"
      description: "Pod {{ $labels.pod }} is restarting frequently"

  - alert: DatabaseConnectionFailure
    expr: up{job="silhouette-workflow-backend"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Backend service is down"
      description: "Backend service is not responding"

  # Security alerts
  - alert: HighFailedLoginRate
    expr: rate(auth_failed_logins_total[5m]) > 10
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "High number of failed login attempts"
      description: "Failed login rate is {{ $value }} per second"

  - alert: SuspiciousAPIUsage
    expr: rate(api_requests_total{status=~"4.."}[5m]) > 50
    for: 3m
    labels:
      severity: warning
    annotations:
      summary: "High number of API errors"
      description: "API error rate is {{ $value }} per second for endpoint {{ $labels.endpoint }}"
```

## 6. Rollback y Recovery

### Auto-Rollback Script

```bash
#!/bin/bash
# scripts/auto-rollback.sh

NAMESPACE=${NAMESPACE:-production}
DEPLOYMENT=${DEPLOYMENT:-silhouette-workflow}
PREVIOUS_REVISION=${PREVIOUS_REVISION}

set -e

echo "Starting rollback process..."
echo "Namespace: $NAMESPACE"
echo "Deployment: $DEPLOYMENT"
echo "Target revision: $PREVIOUS_REVISION"

# Function to check if deployment is healthy
check_deployment_health() {
    local deployment=$1
    local namespace=$2
    
    echo "Checking deployment health for $deployment in $namespace..."
    
    # Check if all pods are ready
    local ready_pods=$(kubectl get pods -n $namespace -l app=$deployment -o jsonpath='{.items[*].status.conditions[?(@.type=="Ready")].status}' | tr ' ' '\n' | grep -c 'True' || echo "0")
    local total_pods=$(kubectl get deployment $deployment -n $namespace -o jsonpath='{.spec.replicas}' || echo "0")
    
    if [ "$ready_pods" -eq "$total_pods" ] && [ "$total_pods" -gt 0 ]; then
        echo "‚úÖ All pods are ready ($ready_pods/$total_pods)"
        return 0
    else
        echo "‚ùå Not all pods are ready ($ready_pods/$total_pods)"
        return 1
    fi
}

# Function to perform rollback
perform_rollback() {
    local deployment=$1
    local namespace=$2
    local target_revision=$3
    
    echo "Performing rollback for $deployment to revision $target_revision..."
    
    # Rollback to previous revision
    if [ -n "$target_revision" ]; then
        kubectl rollout undo deployment/$deployment -n $namespace --to-revision=$target_revision
    else
        kubectl rollout undo deployment/$deployment -n $namespace
    fi
    
    # Wait for rollback to complete
    kubectl rollout status deployment/$deployment -n $namespace --timeout=300s
}

# Function to run health checks
run_health_checks() {
    local namespace=$1
    
    echo "Running health checks..."
    
    # Check endpoint accessibility
    local frontend_url="https://silhouette-workflow.com/health"
    local backend_url="https://silhouette-workflow.com/api/health"
    
    if curl -sf $frontend_url > /dev/null; then
        echo "‚úÖ Frontend health check passed"
    else
        echo "‚ùå Frontend health check failed"
        return 1
    fi
    
    if curl -sf $backend_url > /dev/null; then
        echo "‚úÖ Backend health check passed"
    else
        echo "‚ùå Backend health check failed"
        return 1
    fi
    
    # Check for error logs
    local error_count=$(kubectl logs -n $namespace -l app=$DEPLOYMENT --tail=1000 | grep -i error | wc -l)
    if [ "$error_count" -eq 0 ]; then
        echo "‚úÖ No error logs found"
    else
        echo "‚ö†Ô∏è Found $error_count error logs in the last 1000 lines"
    fi
    
    return 0
}

# Main rollback logic
main() {
    echo "Starting rollback process for Silhouette Workflow..."
    
    # Check current deployment status
    if ! check_deployment_health $DEPLOYMENT $NAMESPACE; then
        echo "Current deployment is unhealthy. Proceeding with rollback..."
    fi
    
    # Get previous revision if not specified
    if [ -z "$PREVIOUS_REVISION" ]; then
        PREVIOUS_REVISION=$(kubectl rollout history deployment/$DEPLOYMENT -n $NAMESPACE | tail -2 | head -1 | awk '{print $1}')
        echo "Using previous revision: $PREVIOUS_REVISION"
    fi
    
    # Perform rollback
    perform_rollback $DEPLOYMENT $NAMESPACE $PREVIOUS_REVISION
    perform_rollback $DEPLOYMENT-frontend $NAMESPACE $PREVIOUS_REVISION
    
    # Wait for new deployment to be ready
    sleep 30
    
    # Check if rollback was successful
    if ! check_deployment_health $DEPLOYMENT $NAMESPACE; then
        echo "‚ùå Rollback failed - deployment is still unhealthy"
        exit 1
    fi
    
    if ! check_deployment_health $DEPLOYMENT-frontend $NAMESPACE; then
        echo "‚ùå Frontend rollback failed - deployment is still unhealthy"
        exit 1
    fi
    
    # Run comprehensive health checks
    if ! run_health_checks $NAMESPACE; then
        echo "‚ùå Health checks failed after rollback"
        exit 1
    fi
    
    # Update load balancer to point to rolled back version
    echo "Updating load balancer configuration..."
    kubectl patch service $DEPLOYMENT -n $NAMESPACE -p '{"spec":{"selector":{"app":"'$DEPLOYMENT'"}}}'
    kubectl patch service $DEPLOYMENT-frontend -n $NAMESPACE -p '{"spec":{"selector":{"app":"'$DEPLOYMENT-frontend'"}}}'
    
    echo "‚úÖ Rollback completed successfully!"
    echo "Deployment rolled back to revision $PREVIOUS_REVISION"
    
    # Send notification
    if [ -n "$SLACK_WEBHOOK_URL" ]; then
        curl -X POST -H 'Content-type: application/json' \
            --data '{"text":"‚úÖ Silhouette Workflow rollback completed successfully!","attachments":[{"color":"good","fields":[{"title":"Namespace","value":"'$NAMESPACE'","short":true},{"title":"Target Revision","value":"'$PREVIOUS_REVISION'","short":true}]}]}' \
            $SLACK_WEBHOOK_URL
    fi
}

# Run main function
main "$@"
```

## M√©tricas del Pipeline

### Dashboard de CI/CD

```json
{
  "dashboard": {
    "title": "Silhouette Workflow CI/CD Dashboard",
    "panels": [
      {
        "title": "Pipeline Success Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "rate(ci_pipeline_runs_total{status=\"success\"}[24h]) / rate(ci_pipeline_runs_total[24h]) * 100",
            "legendFormat": "Success Rate"
          }
        ]
      },
      {
        "title": "Average Deployment Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(ci_deployment_duration_seconds_bucket[24h]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, rate(ci_deployment_duration_seconds_bucket[24h]))",
            "legendFormat": "Median"
          }
        ]
      },
      {
        "title": "Test Coverage",
        "type": "stat",
        "targets": [
          {
            "expr": "test_coverage_percentage",
            "legendFormat": "Coverage"
          }
        ]
      },
      {
        "title": "Deployment Frequency",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(ci_deployments_total[24h])",
            "legendFormat": "Deployments per day"
          }
        ]
      },
      {
        "title": "Mean Time to Recovery",
        "type": "stat",
        "targets": [
          {
            "expr": "avg(ci_mttr_seconds) / 60",
            "legendFormat": "MTTR (minutes)"
          }
        ]
      },
      {
        "title": "Change Failure Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "rate(ci_rollback_total[24h]) / rate(ci_deployments_total[24h]) * 100",
            "legendFormat": "Failure Rate"
          }
        ]
      }
    ]
  }
}
```

## Conclusi√≥n

El **CI/CD Pipeline** de Silhouette Workflow Creation proporciona un sistema de integraci√≥n y despliegue continuo de clase empresarial que garantiza entregas r√°pidas, confiables y seguras. Con automatizaci√≥n completa, testing integral, seguridad avanzada y monitoring robusto, este pipeline establece las bases para un desarrollo √°gil y confiable.

### Beneficios Principales

1. **Automatizaci√≥n Completa**: Desde el c√≥digo hasta la producci√≥n
2. **Calidad Garantizada**: Testing integral en cada etapa
3. **Seguridad Integrada**: Scanning y an√°lisis de seguridad autom√°tico
4. **Monitoreo Robusto**: Observabilidad completa del pipeline
5. **Rollback Autom√°tico**: Recuperaci√≥n r√°pida en caso de problemas
6. **Escalabilidad**: Dise√±o para equipos grandes y alta frecuencia de despliegue
7. **Compliance**: Cumplimiento autom√°tico de est√°ndares de seguridad

### M√©tricas de √âxito

- **Build Success Rate**: 99%+
- **Deployment Success Rate**: 99%+
- **Mean Time to Recovery (MTTR)**: <15 minutos
- **Deployment Time**: <3 minutos
- **Code Coverage**: 95%+
- **Security Scan Pass Rate**: 100%

---

**Autor**: Silhouette Anonimo  
**Versi√≥n**: 1.0.0  
**Fecha**: 2025-11-09  
**Estado**: Implementaci√≥n Completa